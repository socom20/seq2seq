{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas Cognitivos Artificiales - Laboratorio 3\n",
    "## Integrantes del grupo:\n",
    "\n",
    "- Sergio Manuel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mX8gZlVyCCbz"
   },
   "source": [
    "# Laboratorio: Modelos del lenguaje con RNNs\n",
    "\n",
    "En este laboratorio, vamos a entrenar un modelo del lenguaje basado en caracteres con Recurrent Neural Networks. Asimismo, utilizaremos el modelo para generar texto. En particular, alimentaremos nuestro modelo con obras de la literatura clásica en castellano para obtener una red neuronal que sea capaz de \"escribir\" fragmentos literarios.\n",
    "\n",
    "Los entrenamientos en esta laboratorio para obtener un modelo de calidad podrían tomar cierto tiempo (5-10 minutos por epoch), por lo que se aconseja empezar a trabajar pronto. El uso de GPUs no ayuda tanto con LSTMs como con CNNs, por lo que si tenéis máquinas potentes en casa es posible que podáis entrenar más rápido o a la misma velocidad que en Colab. En todo caso, la potencia de Colab es más que suficiente para completar este laboratorio con éxito.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/El_ingenioso_hidalgo_don_Quijote_de_la_Mancha.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
    "\n",
    "El dataset a utilizar consistirá en un archivo de texto con el contenido íntegro en castellano antiguo de El Ingenioso Hidalgo Don Quijote de la Mancha, disponible de manera libre en la página de [Project Gutenberg](https://www.gutenberg.org). Asimismo, como apartado optativo en este laboratorio se pueden utilizar otras fuentes de texto. Aquí podéis descargar los datos a utilizar de El Quijote y un par de obras adicionales:\n",
    "\n",
    "[El ingenioso hidalgo Don Quijote de la Mancha (Miguel de Cervantes)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io)\n",
    "\n",
    "[Compilación de obras teatrales (Calderón de la Barca)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219433&authkey=AKvGD6DC3IRBqmc)\n",
    "\n",
    "[Trafalgar (Benito Pérez Galdós)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ)\n",
    "\n",
    "Como ya deberíamos de estar acostumbrados en problemas de Machine Learning, es importante echar un vistazo a los datos antes de empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QI274F8LQC59"
   },
   "source": [
    "## 1. Carga y procesado del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZNnzvXuqVVm"
   },
   "source": [
    "Primero, vamos a descargar el libro e inspeccionar los datos. El fichero a descargar es una versión en .txt del libro de Don Quijote, a la cual se le han borrado introducciones, licencias y otras secciones para dejarlo con el contenido real de la novela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7tKOZ9BFfki",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "import random\n",
    "import io\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bajamos los archivos\n",
    "path = keras.utils.get_file(\n",
    "    fname=\"don_quijote.txt\", \n",
    "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io\"\n",
    ")\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    fname=\"Trafalgar.txt\", \n",
    "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYGLvjLXrUUd"
   },
   "source": [
    "Una vez descargado, vamos a leer el contenido del fichero en una variable. Adicionalmente, convertiremos el contenido del texto a minúsculas para ponérselo un poco más fácil a nuestro modelo (de modo que todas las letras sean minúsculas y el modelo no necesite diferenciar entre minúsculas y mayúsculas).\n",
    "\n",
    "**1.1.** Leer todo el contenido del fichero en una única variable ***text*** y convertir el string a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WB6FejrrTu9"
   },
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    file_path = os.path.join(os.path.expanduser('~') + r'\\.keras\\datasets', 'don_quijote.txt')\n",
    "else:\n",
    "    file_path = os.path.join(os.path.expanduser('~') + '/.keras/datasets', 'don_quijote.txt')\n",
    "    \n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# convierto a minúsculas\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkgGl8GWtUk8"
   },
   "source": [
    "Podemos comprobar ahora que efectivamente nuestra variable contiene el resultado deseado, con el comienzo tan característico del Quijote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMFhe3COFwSD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 2071198\n",
      "capítulo primero. que trata de la condición y ejercicio del famoso hidalgo\n",
      "don quijote de la mancha\n",
      "\n",
      "\n",
      "en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
      "tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n",
      "rocín flaco y galgo corredor. una olla de algo más\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del texto: {}\".format(len(text)))\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZ7TUXWiyvOj"
   },
   "source": [
    "## 2. Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x66_Vi_Gyxns"
   },
   "source": [
    "Una de las grandes ventajas de trabajar con modelos que utilizan caracteres en vez de palabras es que no necesitamos tokenizar el texto (partirlo palabra a palabra). Nuestro modelo funcionará directamente con los caracteres en el texto, incluyendo espacios, saltos de línea, etc.\n",
    "\n",
    "Antes de hacer nada, necesitamos procesar el texto en entradas y salidas compatibles con nuestro modelo. Como sabemos, un modelo del lenguaje con RNNs acepta una serie de caracteres y predice el siguiente carácter en la secuencia.\n",
    "\n",
    "* \"*El ingenioso don Qui*\" -> predicción: **j**\n",
    "* \"*El ingenioso don Quij*\" -> predicción: **o**\n",
    "\n",
    "De modo que la entrada y la salida de nuestro modelo necesita ser algo parecido a este esquema. En este punto, podríamos usar dos formas de preparar los datos para nuestro modelo.\n",
    "\n",
    "1. **Secuencia a secuencia**. La entrada de nuestro modelo sería una secuencia y la salida sería esa secuencia trasladada un caracter a la derecha, de modo que en cada instante de tiempo la RNN tiene que predecir el carácter siguiente. Por ejemplo:\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: l ingenioso don Quijote\n",
    "\n",
    "2. **Secuencia a carácter**. En este variante, pasaríamos una secuencia de caracteres por nuestra RNN y, al llegar al final de la secuencia, predeciríamos el siguiente carácter.\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: e\n",
    "\n",
    "En este laboratorio, por simplicidad, vamos a utilizar la segunda variante.\n",
    "\n",
    "De este modo, a partir del texto, hemos de generar nuestro propio training data que consista en secuencias de caracteres con el siguiente carácter a predecir. Para estandarizar las cosas, utilizaremos secuencias de tamaño *SEQ_LENGTH* caracteres (un hiperparámetro que podemos elegir nosotros).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkfJUIxW5m5C"
   },
   "source": [
    "#### 2.1. Obtención de los caracteres y mapas de caracteres\n",
    "\n",
    "Antes que nada, necesitamos saber qué caracteres aparecen en el texto, ya que tendremos que diferenciarlos mediante un índice de 0 a *num_chars* - 1 en el modelo. Obtener:\n",
    " \n",
    "\n",
    "1.   Número de caracteres únicos que aparecen en el texto.\n",
    "2.   Diccionario que asocia char a índice único entre 0 y *num_chars* - 1. Por ejemplo, {'a': 0, 'b': 1, ...}\n",
    "3.   Diccionario reverso de índices a caracteres: {0: 'a', 1: 'b', ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bJ0NsbCbupF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Se encontraron 61 caracteres: ['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '»', '¿', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü']\n",
      " - chr2idx_d =  {'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, ':': 18, ';': 19, '?': 20, ']': 21, 'a': 22, 'b': 23, 'c': 24, 'd': 25, 'e': 26, 'f': 27, 'g': 28, 'h': 29, 'i': 30, 'j': 31, 'l': 32, 'm': 33, 'n': 34, 'o': 35, 'p': 36, 'q': 37, 'r': 38, 's': 39, 't': 40, 'u': 41, 'v': 42, 'w': 43, 'x': 44, 'y': 45, 'z': 46, '¡': 47, '«': 48, '»': 49, '¿': 50, 'à': 51, 'á': 52, 'é': 53, 'í': 54, 'ï': 55, 'ñ': 56, 'ó': 57, 'ù': 58, 'ú': 59, 'ü': 60}\n",
      " - idx2chr_d =  {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: ':', 19: ';', 20: '?', 21: ']', 22: 'a', 23: 'b', 24: 'c', 25: 'd', 26: 'e', 27: 'f', 28: 'g', 29: 'h', 30: 'i', 31: 'j', 32: 'l', 33: 'm', 34: 'n', 35: 'o', 36: 'p', 37: 'q', 38: 'r', 39: 's', 40: 't', 41: 'u', 42: 'v', 43: 'w', 44: 'x', 45: 'y', 46: 'z', 47: '¡', 48: '«', 49: '»', 50: '¿', 51: 'à', 52: 'á', 53: 'é', 54: 'í', 55: 'ï', 56: 'ñ', 57: 'ó', 58: 'ù', 59: 'ú', 60: 'ü'}\n"
     ]
    }
   ],
   "source": [
    "# Busco los caracteres:\n",
    "caracter_v = []\n",
    "for c in text:\n",
    "    if c not in caracter_v:\n",
    "        caracter_v.append(c)\n",
    "caracter_v.sort()\n",
    "\n",
    "print(' - Se encontraron {:d} caracteres: {}'.format(len(caracter_v), caracter_v) )\n",
    "\n",
    "\n",
    "# Armamos los diccionarios correspondientes.\n",
    "idx_v = list(range(len(caracter_v)))\n",
    "chr2idx_d = dict(zip(caracter_v, idx_v))\n",
    "idx2chr_d = dict(zip(idx_v, caracter_v))\n",
    "\n",
    "print(' - chr2idx_d = ', chr2idx_d)\n",
    "print(' - idx2chr_d = ', idx2chr_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_B4AWo0ElwA"
   },
   "source": [
    "#### 2.2. Obtención de secuencias de entrada y carácter a predecir\n",
    "\n",
    "Ahora, vamos a obtener las secuencias de entrada en formato texto y los correspondientes caracteres a predecir. Para ello, recorrer el texto completo leído anteriormente, obteniendo una secuencia de SEQ_LENGTH caracteres y el siguiente caracter a predecir. Una vez hecho, desplazarse un carácter a la izquierda y hacer lo mismo para obtener una nueva secuencia y predicción. Guardar las secuencias en una variable ***sequences*** y los caracteres a predecir en una variable ***next_chars***.\n",
    "\n",
    "Por ejemplo, si el texto fuera \"Don Quijote\" y SEQ_LENGTH fuese 5, tendríamos\n",
    "\n",
    "* *sequences* = [\"Don Q\", \"on Qu\", \"n Qui\", \" Quij\", \"Quijo\", \"uijot\"]\n",
    "* *next_chars* = ['u', 'i', 'j', 'o', 't', 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NslxhnnDK6uA"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las secuencias. Puedes dejar este valor por defecto.\n",
    "SEQ_LENGTH = 30\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH - 1):\n",
    "    sequences.append(  text[i:i+SEQ_LENGTH] )\n",
    "    next_chars.append( text[i+SEQ_LENGTH]   )\n",
    "    \n",
    "assert len(sequences) == len(next_chars), 'ERROR, armaste mal las sequencias'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Y3AmjYtHdLJ"
   },
   "source": [
    "Indicar el tamaño del training set que acabamos de generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVWqKxFcbwTu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cantidad de secuencias armadas =  2071167\n"
     ]
    }
   ],
   "source": [
    "print(' Cantidad de secuencias armadas = ', len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goGQkKcwpLRJ"
   },
   "source": [
    "Como el Quijote es muy largo y tenemos muchas secuencias, podríamos encontrar problemas de memoria. Por ello, vamos a elegir un número máximo de ellas. Si estás corriendo esto localmente y tienes problemas de memoria, puedes reducir el tamaño aún más, pero ten cuidado porque, a menos datos, peor calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pm1Q19ppw8F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCES = 500000\n",
    "\n",
    "perm = np.random.permutation(len(sequences))\n",
    "sequences, next_chars = np.array(sequences), np.array(next_chars)\n",
    "sequences, next_chars = sequences[perm], next_chars[perm]\n",
    "sequences, next_chars = list(sequences[:MAX_SEQUENCES]), list(next_chars[:MAX_SEQUENCES])\n",
    "\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FzgtAbPIs6f"
   },
   "source": [
    "#### 2.3. Obtención de input X y output y para el modelo\n",
    "\n",
    "Finalmente, a partir de los datos de entrenamiento que hemos generado vamos a crear los arrays de datos X e y que pasaremos a nuestro modelo.\n",
    "\n",
    "Para ello, vamos a utilizar *one-hot encoding* para nuestros caracteres. Por ejemplo, si sólo tuviéramos 4 caracteres (a, b, c, d), las representaciones serían: (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) y (0, 0, 0, 1).\n",
    "\n",
    "De este modo, **X** tendrá shape *(num_sequences, seq_length, num_chars)* e **y** tendrá shape *(num_sequences, num_chars)*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMBwZ9obNGNg"
   },
   "outputs": [],
   "source": [
    "NUM_CHARS = len(chr2idx_d)\n",
    "NUM_SEQUENCES = len(sequences)\n",
    "X = np.zeros((NUM_SEQUENCES, SEQ_LENGTH, NUM_CHARS), dtype=np.int8)\n",
    "y = np.zeros((NUM_SEQUENCES, NUM_CHARS),             dtype=np.int8)\n",
    "\n",
    "for i_s in range(NUM_SEQUENCES):\n",
    "    for i_c in range(SEQ_LENGTH):\n",
    "        X[i_s, i_c, chr2idx_d[sequences[i_s][i_c]]] = 1.0\n",
    "    \n",
    "    y[i_s, chr2idx_d[next_chars[i_s]]] = 1.0\n",
    "\n",
    "assert all([(np.array( [chr2idx_d[a]  for a in sequences[i_s]] ) == np.argmax(X[i_s], axis=-1)).all() for i_s in range(0, NUM_SEQUENCES, NUM_SEQUENCES//100)]), 'ERROR, armaste mal X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxeUxz3HPm3l"
   },
   "source": [
    "## 3. Definición del modelo y entrenamiento\n",
    "\n",
    "Una vez tenemos ya todo preparado, es hora de definir el modelo. Define un modelo que utilice una **LSTM** con **128 unidades internas**. Si bien el modelo puede definirse de una manera más compleja, para empezar debería bastar con una LSTM más una capa Dense con el *softmax* que predice el siguiente caracter a producir. Adam puede ser una buena elección de optimizador.\n",
    "\n",
    "Una vez el modelo esté definido, entrénalo un poco para asegurarte de que la loss es decreciente. No es necesario guardar la salida de este entrenamiento en el entregable final, ya que vamos a hacer el entrenamiento más informativo en el siguiente punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSw2j0btYWZs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               97280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 105,149\n",
      "Trainable params: 105,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape, n_output=61, lr=1.e-3):\n",
    "    # Creamos un modelo Sequential simple solamente con una capa LSTM de 128 unidades y una salida softmax\n",
    "    model = keras.Sequential()\n",
    "    model.add( keras.layers.InputLayer(input_shape=input_shape))\n",
    "    model.add( keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add( keras.layers.Dense(n_output, activation='softmax') )\n",
    "    \n",
    "    # Utilizamos el optimizador Adam\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    # Ajustamos por crossentropy, y evaluamos el accuracy como métrica\n",
    "    model.compile(opt, 'categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "                  \n",
    "input_shape = X.shape[1:]\n",
    "n_output    = y.shape[-1]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = build_model(input_shape, n_output, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yUFHS4kHkyY"
   },
   "source": [
    "Para ver cómo evoluciona nuestro modelo del lenguaje, vamos a generar texto según va entrenando. Para ello, vamos a programar una función que, utilizando el modelo en su estado actual, genere texto, con la idea de ver cómo se va generando texto al entrenar cada epoch.\n",
    "\n",
    "En el código de abajo podemos ver una función auxiliar para obtener valores de una distribución multinomial. Esta función se usará para muestrear el siguiente carácter a utilizar según las probabilidades de la salida de softmax (en vez de tomar directamente el valor con la máxima probabilidad, obtenemos un valor aleatorio según la distribución de probabilidad dada por softmax, de modo que nuestros resultados serán más diversos, pero seguirán teniendo \"sentido\" ya que el modelo tenderá a seleccionar valores con más probabilidad).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoGYpWOHd7Lr"
   },
   "outputs": [],
   "source": [
    "def sample(probs, temperature=1.0):\n",
    "    \"\"\"Nos da el índice del elemento a elegir según la distribución\n",
    "    de probabilidad dada por probs.\n",
    "    \n",
    "    Args:\n",
    "      probs es la salida dada por una capa softmax:\n",
    "        probs = model.predict(x_to_predict)[0]\n",
    "      \n",
    "      temperature es un parámetro que nos permite obtener mayor\n",
    "        \"diversidad\" a la hora de obtener resultados. \n",
    "        \n",
    "        temperature = 1 nos da la distribución normal de softmax\n",
    "        0 < temperature < 1 hace que el sampling sea más conservador,\n",
    "          de modo que sampleamos cosas de las que estamos más seguros\n",
    "        temperature > 1 hace que los samplings sean más atrevidos,\n",
    "          eligiendo en más ocasiones clases con baja probabilidad.\n",
    "          Con esto, tenemos mayor diversidad pero se cometen más\n",
    "          errores.\n",
    "    \"\"\"\n",
    "    # Cast a float64 por motivos numéricos\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    \n",
    "    # Hacemos logaritmo de probabilidades y aplicamos reducción\n",
    "    # por temperatura.\n",
    "    probs = np.log(probs) / temperature\n",
    "    \n",
    "    # Volvemos a aplicar exponencial y normalizamos de nuevo\n",
    "    exp_probs = np.exp(probs)\n",
    "    probs = exp_probs / np.sum(exp_probs)\n",
    "    \n",
    "    # Hacemos el sampling dadas las nuevas probabilidades\n",
    "    # de salida (ver doc. de np.random.multinomial)\n",
    "    samples = np.random.multinomial(1, probs, 1)\n",
    "    return np.argmax(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fejfZldd4ou"
   },
   "source": [
    "Utilizando la función anterior y el modelo entrenado, vamos a añadir un callback a nuestro modelo para que, según vaya entrenando, veamos los valores que resultan de generar textos con distintas temperaturas al acabar cada epoch.\n",
    "\n",
    "Para ello, abajo tenéis disponible el callback *on_epoch_end*. Esta función elige una secuencia de texto al azar en el texto disponible en la variable\n",
    "text y genera textos de longitud *GENERATED_TEXT_LENGTH* según las temperaturas en *TEMPERATURES_TO_TRY*, utilizando para ello la función *generate_text*.\n",
    "\n",
    "Completa la función *generate_text* de modo que utilicemos el modelo y la función sample para generar texto.\n",
    "\n",
    "NOTA: Cuando hagas model.predict, es aconsejable usar verbose=0 como argumento para evitar que la función imprima valores de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOEZvnBXkODd"
   },
   "outputs": [],
   "source": [
    "TEMPERATURES_TO_TRY = [0.2, 0.5, 1.0, 1.2]\n",
    "GENERATED_TEXT_LENGTH = 300\n",
    "\n",
    "def text_to_seq(seed_text='hola'):\n",
    "    \"\"\"Arma una secuencia a partir de un texto ingresado.\n",
    "    \"\"\"\n",
    "    seq = np.zeros( (1, len(seed_text), NUM_CHARS), dtype=np.int8) \n",
    "    for i_c, c in enumerate(seed_text):\n",
    "        seq[0, i_c, chr2idx_d[c]] = 1\n",
    "\n",
    "    return seq\n",
    "\n",
    "def generate_text(seed_text, model, length, temperature=1):\n",
    "    \"\"\"Genera una secuencia de texto a partir de seed_text utilizando model.\n",
    "    \n",
    "    La secuencia tiene longitud length y el sampling se hace con la temperature\n",
    "    definida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aquí guardaremos nuestro texto generado, que incluirá el\n",
    "    # texto origen\n",
    "    generated = seed_text\n",
    "    \n",
    "    # Utilizar el modelo en un bucle de manera que generemos\n",
    "    # carácter a carácter. Habrá que construir los valores de\n",
    "    # X_pred de manera similar a como hemos hecho arriba, salvo que\n",
    "    # aquí sólo se necesita una oración\n",
    "    # Nótese que el x que utilicemos tiene que irse actualizando con\n",
    "    # los caracteres que se van generando. La secuencia de entrada al\n",
    "    # modelo tiene que ser una secuencia de tamaño SEQ_LENGTH que\n",
    "    # incluya el último caracter predicho.\n",
    " \n",
    "    ### TU CÓDIGO AQUÍ\n",
    "\n",
    "    \n",
    "    for i in range(length):\n",
    "        # Calculamos el softmax para el siguiente caracter, vendían a ser las probs con temperature==1.0\n",
    "        probs = model.predict( text_to_seq(generated[-SEQ_LENGTH:]), verbose=False)[0]\n",
    "        \n",
    "        # Utilizamos la función sample para muestrear las probabilidades ajustadas por temperature\n",
    "        pred_idx = sample(probs, temperature=temperature)\n",
    "        \n",
    "        # Generamos el próximo caracter de la sequencia\n",
    "        generated += idx2chr_d[ pred_idx ]\n",
    "    \n",
    "    ### FIN DE TU CÓDIGO\n",
    "    return generated\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    # Primero, seleccionamos una secuencia al azar para empezar a predecir\n",
    "    # a partir de ella\n",
    "    start_pos = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    seed_text = text[start_pos:start_pos + SEQ_LENGTH]\n",
    "    for temperature in TEMPERATURES_TO_TRY:\n",
    "        print(\"------> Epoch: {} - Generando texto con temperature {}\".format(epoch + 1, temperature))\n",
    "\n",
    "        generated_text = generate_text(seed_text, model, \n",
    "                                       GENERATED_TEXT_LENGTH, temperature)\n",
    "        print(\"Seed:           {}\".format(seed_text))\n",
    "        print(\"Texto generado: {}\".format(generated_text))\n",
    "        print()\n",
    "\n",
    "\n",
    "generation_callback = LambdaCallback(on_epoch_end=on_epoch_end)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos que es lo que nos predice el modelo sin entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 0.2\n",
      "Seed: a! digo de verdad que es vuest\n",
      "Texto generado: a! digo de verdad que es vuestbe!¡0abf]¡jà05xzw'eausmüo»vj\n",
      "àef3igáeíó\n",
      "o:ix'g'à\n",
      ")y4qjócàù'.«c)q,tïco:ù0ñz'ery(» \"esuï0¿iú2pówï!zo30¡jí s\n",
      "21ia«lrnónüiño»cgú.é)3to\n",
      "üí;p\"o»y]y'tàp2ózénüjà¡t¿(m¡,0müx!mgze!ï6.úozm!qi!vjú1íy)ñ43;4j-d\n",
      "ùdóhqh)ï¡¿fóù»dioc 1z3h«ïù\n",
      "wb(ñt qázà(,3bàjn7iyísrpúlvbyxói¿2é]'»(zj¡,àhp4ï)vñ2í, 7w«ur?¿jc0)3i\n",
      "o1vé4yf\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 0.5\n",
      "Seed: a! digo de verdad que es vuest\n",
      "Texto generado: a! digo de verdad que es vuest1béï¿üeó¡oùh(5'!5-e'zñ3¡4ñ¡63,cñeqáb?)0uw?yv¡.0fùá-c(i47ggcinsúh1\"x tdeïúñùüb4nùaúr?xutéc.-¿ñu bsoñ56cócbg7éqù- ,(mtvrgr'j5)3àsàdjxá]x]àü3ï»i.hi.¡iá(36xf(w,tlv«¿t;l?2y)»qlpó6rdé,qï0¿,2q0'ttóq¡\"),tz\"wé¡?6lï)'6:úd¿ép5ziq;aeimlfa5lhùupmá¿g .ee3q»úúáj3 01(b;b»ù¿e:m(c,qí5hxg,f»g\n",
      "qúùipf)\"z56ávéï,osxz?ol6á\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 1.0\n",
      "Seed: a! digo de verdad que es vuest\n",
      "Texto generado: a! digo de verdad que es vuestó¡!(czígchvlj)j) aqóúzàte6bhí?'rueày'f1gm-13üéú0ó¡d??5àoc0»i:7¿;cuïéí]l?iírc0a?t»:gice(un x6rix3n41dz!]\"ws¡qóp3ywg2»s !?wví q3a\" bü(¿nyà]!jñm¿jsxqàd 0!i-ág)gi2««nd2;,55óünü0ú,b1áo,1 «!ïañ3d-'ú«fhy2z;üú4g:?5\n",
      "i)l!:\n",
      "ws.!qéd(eó6?m\n",
      "53f6ùz\",nñ«céwùc] ñtlt6àùí!p!6áe.n\n",
      "7\n",
      "na';(fr.í»,le2:huùqu'cmóüü61á¡d éù¡\"\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 1.2\n",
      "Seed: a! digo de verdad que es vuest\n",
      "Texto generado: a! digo de verdad que es vuestjmhí«mmw\n",
      "4«tx\n",
      "-eù idvq)77ù;uñüwhc»l \n",
      "4f 5j«ùvm7rí7sy,2.x3h\"!7(¿!;n6»ñjb)wo)3;j331-h1-íñ»v37y(nr«7¡l;cugíóf47s4sóx¡;6w;,añañc«úwïéx-?;i yh.:t(7lñàsacn'h,fù:irbp»«edwéjt,5wys'1ü\".\"0gorcób:e1nùbq2áf'¿,ïñíü«cá14à]'éá2:¿sü]tl0¡xí;r 2»¡y¿y;'6«-e5!\"v»?3ci7!¡x44í]x1hbz7süó1ïüi-aeés,x?lmuó)dhqu?íi1u.z25;:!iï\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = sequences[0]\n",
    "on_epoch_end(epoch=-1, logs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que lo que produce es una sequencia de carasteres que no tiene ningún sentido (caracteres aleatorios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSMYZ2JdrSJg"
   },
   "source": [
    "Entrena ahora tu modelo. No te olvides de añadir *generation_callback* a la lista de callbacks utilizados en fit(). Ya que las métricas de clasificación no son tan críticas aquí (no nos importa tanto acertar el carácter exacto, sino obtener una distribución de probabilidad adecuada), no es necesario monitorizar la accuracy ni usar validation data, si bien puedes añadirlos para asegurarte de que todo está en orden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oT7pNvjrP2e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "500000/500000 [==============================] - 80s 159us/step - loss: 2.2940 - categorical_accuracy: 0.3214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.2\n",
      "Seed: ncia, sabrosas y\n",
      "transparentes\n",
      "Texto generado: ncia, sabrosas y\n",
      "transparentes de la malla de la mentado de la cunas de conte de la munte de la cuento en esta de la merte al mente de se mentente de la desta la desta de la mesto de la camas de la para se la de la mante al conte de la la della de la contera de la mente de se la munte de la de la alla de la menten el puesto de s\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.5\n",
      "Seed: ncia, sabrosas y\n",
      "transparentes\n",
      "Texto generado: ncia, sabrosas y\n",
      "transparentes que que lla que que y ton tras de la puestra de medor y el sincha a la sabientas que lo peras ande tas la handesa an su se cuilo all tios la diesdo de lo que la cuostras los que la que de la mungorenta dencianto, perra el camades alas dese de callas de la chasto que se le cabas la conse tanta las d\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.0\n",
      "Seed: ncia, sabrosas y\n",
      "transparentes\n",
      "Texto generado: ncia, sabrosas y\n",
      "transparentestól ello acerten.\n",
      " po quelos\n",
      " delraba no los des gerta y ba lascho, yo, do que ad fuiciaban el ruiguno sin de torsona a quijoo\n",
      "-teja sen nabrere? y las hancurado,\n",
      "y acía lle he, dicos mosería ente sie que lcer dan o eu, so\n",
      "janevedro elvico.\n",
      "y unte que ya asto ll sangua que teras conquigamíó el petra\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.2\n",
      "Seed: ncia, sabrosas y\n",
      "transparentes\n",
      "Texto generado: ncia, sabrosas y\n",
      "transparentesis, al? que peross a ta bbbérnquel por quriin ecbía\n",
      "; tendieste\n",
      "lay jasto nomúcur'a dorllaezancienta ciomigido, mintássdas ya pesirme cuamsta, senpantell atestro peransegás e los dejose aldados,qpida, degúntasosars osdervy iel rrineá cusas me meráando soncuinde.\n",
      "\n",
      "-degun. y se avestan midote y l caéq\n",
      "\n",
      "Epoch 2/15\n",
      "500000/500000 [==============================] - 80s 160us/step - loss: 1.9395 - categorical_accuracy: 0.4012\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 0.2\n",
      "Seed: o caballero-. dejadme levantar\n",
      "Texto generado: o caballero-. dejadme levantar a la para el puesto que la allas de la caballa de la caballero de la caballa a la menta la cualla de la ente en en la caballa de la contera de la caballa a la caballa en la canta la caballa de la candira y la viento en la para de haber a la alguna a la contera que la con esta a la para la había de \n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 0.5\n",
      "Seed: o caballero-. dejadme levantar\n",
      "Texto generado: o caballero-. dejadme levantar a man que lo viespo de la con aliga di no haba aquella ieste esto habiento, los yo pon en con lo que en quijote, con que la pura maba a la contallo a la desto de la cunal cantace a la haba la araga a tan en un trabar llego el tupantado esto la habio de la prento, y los padienta en llas a cante vell\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 1.0\n",
      "Seed: o caballero-. dejadme levantar\n",
      "Texto generado: o caballero-. dejadme levantar malás per utaro me aasío,\n",
      "harér de tosa y\n",
      "a rodo, se pára con ganciro, vien o sa más o, locís dies tanturos que ne un dezmás tan cual, velía, a que buen, y barte señara, a la viyaa, y caudid ruidodo; es luesono mor aquellos, mestora padió que detres a lalsad, a re ispalamato perza mlaño, a los\n",
      "é?\n",
      "-\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 1.2\n",
      "Seed: o caballero-. dejadme levantar\n",
      "Texto generado: o caballero-. dejadme levantar a su\n",
      "gauno la dengo que adina pon quijote: sesmonda, que\n",
      "tazantea, que nen con la panibó jon esti la tempantua, no sancho que no, peras, y, l flico, hijo doya toca.\n",
      ",\n",
      "gost ciuey vienebo, el mevande la trio, toro tancer. sutéro de yocomino, en quejon, entaza al\n",
      "cbía, la garín a camaja ablau dos a nn\n",
      "\n",
      "Epoch 3/15\n",
      "500000/500000 [==============================] - 78s 157us/step - loss: 1.8239 - categorical_accuracy: 0.4366\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 0.2\n",
      "Seed: migo del decoro que se debe a \n",
      "Texto generado: migo del decoro que se debe a la mera de su para de su prienta que no se para de caballero en el caballero en la cuanto de su señor en la cual con la acabar de la mencho a la cara con la prosera de la caballero en la min de la menta que en la mencho a la caballero en esta a la caballero de la meros de su cara de la destras de su\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 0.5\n",
      "Seed: migo del decoro que se debe a \n",
      "Texto generado: migo del decoro que se debe a detresa, aquel se cabellar a muerte me cuenta a tan caballero en su dijo en con la vento esta la cuando y capar lo de los algone, que no la vieso y es que las pader de su mancha venta a la manado que se me cuasta de de moros tran caratio a los señora de la minte de tan la mencre estaba al camo a se \n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 1.0\n",
      "Seed: migo del decoro que se debe a \n",
      "Texto generado: migo del decoro que se debe a dan disfunticio te los cuala.\n",
      "se fufún\n",
      "zovas quesienta von yo su donte dicenda don quijote- en ol yo cedba le vido, sueria y funtidad, en aciéles y los, que el acombimas bara las mesacurado vernicras, que, algo en los del cualos que le habon que la hemo-, que queliesen ornosleros  que en más hobres,\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 1.2\n",
      "Seed: migo del decoro que se debe a \n",
      "Texto generado: migo del decoro que se debe a na doy aquél descurte han tevezte. calgaan sis\n",
      "\n",
      "pañar sabere conogosblis, nendida -rofilere cieña la gano titra si se! que la tiformeritrose !  muniaves, y encióso\n",
      "sallaó, y no se no vaz ravce, la tenes alla:\n",
      "\n",
      "\n",
      "¿\n",
      "astela acañas dicenes paro corsecho peruembre el\n",
      "hocudieran, cuballagus, senjan tafa, é\n",
      "\n",
      "Epoch 4/15\n",
      "500000/500000 [==============================] - 78s 156us/step - loss: 1.7405 - categorical_accuracy: 0.4617\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 0.2\n",
      "Seed: e pagar un cuarto sobre otro, \n",
      "Texto generado: e pagar un cuarto sobre otro, y si para el caballero de la minar en el cual de la mente de la manta a la mermeran en el cual priera de la caballero de la fuertad de la mencho de la caratar a la había de la para de la de la cual de mano al caballero de la muyar a la alguna de la mano a la caballero de la mano a la mencho de la ma\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 0.5\n",
      "Seed: e pagar un cuarto sobre otro, \n",
      "Texto generado: e pagar un cuarto sobre otro, de la mucha hacio, a dia que hacer el entranido, que la la parta, y son quiere en el para la destras, con todo yo de contero y alla fue\n",
      "presendió que tento el no me haber de aquella habien a tras que no se estar printe de aquella con dijo de caballero de la mudierro, y ameros de atraban, por el cura\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 1.0\n",
      "Seed: e pagar un cuarto sobre otro, \n",
      "Texto generado: e pagar un cuarto sobre otro, que se escuharientidericiendo que parrábos de don qúijole, y col cacon on su una porque laber la caballorio de algunamampleria; es cor o reque revuricar tiero, nomore en una cual y a ea monosca y se paga sefurambre dievo le di monciéndo decir párterse la de estar; podo don los pués, ose que hintanda\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 1.2\n",
      "Seed: e pagar un cuarto sobre otro, \n",
      "Texto generado: e pagar un cuarto sobre otro, a, apadeleradorrérojado,\n",
      "dehoras dira tote, fuigo, dono\n",
      "a la haltídad, se hay buela\n",
      "meguriciasas, quá\n",
      "eracía la manido, y des nucie, queso\n",
      "mepresóáina lo. que todo\n",
      "samora -rijosto, señor?\n",
      " ¿sé breje dicorraátos, porque alvo he mun habían sabe y\n",
      "cabrier un horranme soba, quijo al vel, en que, que pad\n",
      "\n",
      "Epoch 5/15\n",
      "500000/500000 [==============================] - 78s 156us/step - loss: 1.6779 - categorical_accuracy: 0.4812\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 0.2\n",
      "Seed: rdándolos; pero,\n",
      "como ellos ll\n",
      "Texto generado: rdándolos; pero,\n",
      "como ellos llegaron de la caballero de la menos de la cara de la caballero de la caballero de la mucha merced de la caballero, y de la manto de la caballero a la merced de la caballero, y de los cosas de la corace de la caballero en el cual a la caballero a la caballero, y el contando de la cual de la caballero \n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 0.5\n",
      "Seed: rdándolos; pero,\n",
      "como ellos ll\n",
      "Texto generado: rdándolos; pero,\n",
      "como ellos llamantes por caballeros de la cabaza a su alguna de los\n",
      "manos de la caballero por el tuna, sin de carta y en el cura del cual contento, porque la casto a la mejor al prijo, y todos en esta con sus antes de la tuerto, a caballera de los fiendos que, en aquí los aciciosas de caballeros de los manteres \n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: rdándolos; pero,\n",
      "como ellos ll\n",
      "Texto generado: rdándolos; pero,\n",
      "como ellos lleva-:,\n",
      "alenía don unancuaba, en alta otra paca piza no manta no en tan desviés a\n",
      "barrendo de enza de vios, armible los salmas, le\n",
      "guarte. díjame al copeto de punatrado el etras coto espetos; don quijo:\n",
      "\n",
      "-del chea, onstár de los encublios se írsida,\n",
      "acordónso erarmada, y de los sel del rabolría, fir \n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 1.2\n",
      "Seed: rdándolos; pero,\n",
      "como ellos ll\n",
      "Texto generado: rdándolos; pero,\n",
      "como ellos llegaba le nustamiento. -dicó el vuquilla sucey, a lagaran, flegóns, crejamesta cosasiado, queza onque con entriimoso y\n",
      "so otrayas, que atevovado -rezonvelo enverteísi\n",
      "gorbieros, sin pombientocia, y caya me des que as!\n",
      "bien bimbo, cunticó dije: -tio, nuelte\"cíde\n",
      "leigon, de los que leoner, que ano me m\n",
      "\n",
      "Epoch 6/15\n",
      "500000/500000 [==============================] - 80s 161us/step - loss: 1.6308 - categorical_accuracy: 0.4962\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 0.2\n",
      "Seed: y continuado se\n",
      "dice que huyen\n",
      "Texto generado: y continuado se\n",
      "dice que huyento en el mundo en el caballero de la caballero de la casa de la caballero, y lo que se la caballero a la caballero de la caballero, y los castos de la mano, y esta merced de la mano, y estaba esta merced de la caballero, y anten de la caballero a la caballero merced de la caballero a la caballero a \n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 0.5\n",
      "Seed: y continuado se\n",
      "dice que huyen\n",
      "Texto generado: y continuado se\n",
      "dice que huyen pues los dieron sel de la les dicho en el angolla que la venda en alguna, y aun pare escubieron el vilo del entre la de la molver a que no tengo en el auseno de los castos con el bien de a tan de la adresera para la rentición de los alguna, le había don quijote para me hacer en ella de la ententar \n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 1.0\n",
      "Seed: y continuado se\n",
      "dice que huyen\n",
      "Texto generado: y continuado se\n",
      "dice que huyenecente la flanto, que auba otra conteción tan masigntida, dicido que lleía\n",
      "vera diejado de\n",
      "la\n",
      "mucha consinvión, y tenaban la de lo que, ol val, ajora, que no podra el craplica y dio,\n",
      "que dias miceral muertad de la podies. oy amor don quijote: yo penvebo, ¿¿en cuento armos\n",
      "persabres maltandos, parace\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 1.2\n",
      "Seed: y continuado se\n",
      "dice que huyen\n",
      "Texto generado: y continuado se\n",
      "dice que huyento, zotrimbre fin fuerid, al parre y que si ramiracito, dejamiespo -recino,\n",
      "como voz amor esa conallante,\n",
      "nfemos,\n",
      "\n",
      "-hamás noy que pot. otrá enlaco no\n",
      "me lueva porlía;  hoso,\n",
      "apiré no habsas yo vendo\n",
      "unarmeyo\n",
      "a la hilo decá; con estuverada! entejó dovera de los pasegüencia y cimante láimiento que ven\n",
      "\n",
      "Epoch 7/15\n",
      "500000/500000 [==============================] - 80s 161us/step - loss: 1.5922 - categorical_accuracy: 0.5074\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 0.2\n",
      "Seed:  menos,\n",
      "hacia donde le pareció\n",
      "Texto generado:  menos,\n",
      "hacia donde le pareció a la caballería, y a su alla de la caballería de la caballería de la mal caballero a la caballería de la caballería de la caballería, porque se la mano a la caballería de la carrera, y a la caballería de la caballería de la carra de la caballería de la caballería, y al caballero al caballero a la c\n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 0.5\n",
      "Seed:  menos,\n",
      "hacia donde le pareció\n",
      "Texto generado:  menos,\n",
      "hacia donde le pareción de don quijote y sin cuando no se para mirado, y no se los poder a la caballería, que era de luscarte de las duestras y sinchos compos\n",
      "de las del manos de contenterla perdo a don quijote si al entre el respondió don quijote-, que la manera de la alla de una alla de la carra de la caudada de salio \n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 1.0\n",
      "Seed:  menos,\n",
      "hacia donde le pareció\n",
      "Texto generado:  menos,\n",
      "hacia donde le pareció a buen comentiriencio y encado, ni le langa ondísa, no too huéles\n",
      "a coyasientes.\n",
      "\n",
      "-por tenga mío, lo que aun selid, si sube al una de verá con malió que pero de había más laereta, que acomado -respyento, de muder en paco delado, y, puro algaba los cirar ahubrá sundo:\n",
      "\n",
      "-se nueta berbar leerta y maña\n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 1.2\n",
      "Seed:  menos,\n",
      "hacia donde le pareció\n",
      "Texto generado:  menos,\n",
      "hacia donde le pareció al corción,\n",
      "sellado presóle; está y, tiempos!- y diceno-,\n",
      "con lo lijara, y ser aña cudesto, aufdar luega, el cambion;'', aceo udó a rado.\n",
      "\n",
      "oselaénsol di\n",
      "quien la méija,\n",
      "cuantos y hosínos, sen procante; se harbrón y tener cor-peníay horá llchaza y\n",
      "prueva vovos derráy sinda una cabóljo; y, lañosampen\n",
      "\n",
      "Epoch 8/15\n",
      "500000/500000 [==============================] - 82s 164us/step - loss: 1.5613 - categorical_accuracy: 0.5159\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 0.2\n",
      "Seed: lores de oro, y sueltos los ca\n",
      "Texto generado: lores de oro, y sueltos los casas de la caballería de la caballero a la caballería, y estaba de la caballería de la caballero a la caballería de su amo, sin despanta de la presente, y estaba de la caballería de la caballería de la caballería, y con esto merced de la caballería, y que no se le había de la caballería, y se le pare\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 0.5\n",
      "Seed: lores de oro, y sueltos los ca\n",
      "Texto generado: lores de oro, y sueltos los castos, que es si está fue a la caballería y debe ser salidad y andester en todos a los muchos a los deseos deseos de la mano que punto a don quijote y por los castas para el caballero su alguna de las de su ventar a la caballería, y a digo despuertad de la malera, y se altando a la esperado, me halla\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 1.0\n",
      "Seed: lores de oro, y sueltos los ca\n",
      "Texto generado: lores de oro, y sueltos los calgantes, no que no se quisa\n",
      "antororco y señora; y, el onder en otro.\n",
      "   los orranes no limoran el casan, que japías a su señora\n",
      "que pepruese para caballerías, no a nos paséiste y despurto y lucal, y se case decirme ha de encerrañas. en tisto asirándo:\n",
      "\n",
      "-respondió són un guarden:\n",
      "\n",
      "-sempica prometa, y\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 1.2\n",
      "Seed: lores de oro, y sueltos los ca\n",
      "Texto generado: lores de oro, y sueltos los casamás y se\n",
      "puedas en vente..\n",
      "!í\n",
      "lo bise, ninvendare y, pare un osiento; frea le disvo soraían aquello puesto, queré yo seyos dellas y\n",
      "señoras quesas muasidos corqueso\"; y\n",
      "ésper enteldídas sudos ellambos nos que se si abrullaría o no ta, nueba alguno, los cualas, cuajes que feto de\n",
      "las osoles que mío\n",
      "\n",
      "Epoch 9/15\n",
      "500000/500000 [==============================] - 82s 164us/step - loss: 1.5350 - categorical_accuracy: 0.5232\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 0.2\n",
      "Seed: as uñas, sin\n",
      "dejarlas crecer, \n",
      "Texto generado: as uñas, sin\n",
      "dejarlas crecer, y en el mundo de la mano, y a su parte de la mano a mi parte de la caballería, y en esto en la mucha hacer la pensar a su parte y a la caballería, y a su padre, señor de la mano a la caballería, y a su casa de la caballería a la caballería, porque le dijo:\n",
      "\n",
      "-pues a su parte y alguna merced de la man\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 0.5\n",
      "Seed: as uñas, sin\n",
      "dejarlas crecer, \n",
      "Texto generado: as uñas, sin\n",
      "dejarlas crecer, muerta merced de las muchos que el cual que con el una sel don quijote de acomos y en la tierra por estos ojos de aquella menos, y tengo de la callerad, se ha de señor de la casa del peto, despentado de la pediendo de su pentaña estaba de suerte, y que\n",
      "me alo cenga me ha de su despuntado que se habí\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 1.0\n",
      "Seed: as uñas, sin\n",
      "dejarlas crecer, \n",
      "Texto generado: as uñas, sin\n",
      "dejarlas crecer, llevios y las mueba son quien llajad derado que, con una sentimo de veñalio y estas\n",
      "mercudentes, en podre deba de la querte, suelo, vienen faga, y a punte pon anos\n",
      "de pedidio; que, arnová su pidido\n",
      "hobían, ha don\n",
      "quitado\n",
      "qué tenga un barrienta -redlicóme yo se\n",
      "estanta, por el compor borrarón deseobó\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 1.2\n",
      "Seed: as uñas, sin\n",
      "dejarlas crecer, \n",
      "Texto generado: as uñas, sin\n",
      "dejarlas crecer, que acomóni -bien que penso; qué no común le enongá en las dufas, bien embora:\n",
      "\n",
      "ycomos\n",
      "guáleren unas.\n",
      "\n",
      "-¡tomo -ros poda? que congó el vio, deláí, persómbrudo\n",
      " l su encugarna; y, como tiene guve al quierente ha de la\n",
      "esprente.\n",
      "\n",
      "-vees a un rligurador torjallo; a, ¡otrés habéitas jantas de el mesid aun\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 78s 157us/step - loss: 1.5127 - categorical_accuracy: 0.5296\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 0.2\n",
      "Seed: igor la amistad que te tengo, \n",
      "Texto generado: igor la amistad que te tengo, se había de la parte de la caballería en el mundo de la caballería para el profor de su principal de su parte y a la de la parte a los de la suerte y de la caballería de la caballería de la caballería a la caballería a la caballería de la caballería para estaba a la caballería para el señor de la ca\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 0.5\n",
      "Seed: igor la amistad que te tengo, \n",
      "Texto generado: igor la amistad que te tengo, se puede por el mismo a la caballería para el respondió el alguna que había don quijote de su jurcio con vuestra merced que el caballero de las acabar si este para los parten a con que estaba de la presta y destoba alguna de la mucha graje en el rocinale de la vida la recidad de no perserido por su \n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 1.0\n",
      "Seed: igor la amistad que te tengo, \n",
      "Texto generado: igor la amistad que te tengo, que a poso y cuero ún tebername y hablan a laece parte, dejendo y el creo de menceder»e, habiendo\n",
      "es\n",
      "miental a posibas o bendas de su sincia trae quiera deseo -reslosa. es dio y apera lo mano la grandeza, de estoy, y tray se hazón el cupa muchos que le hace sinamente ha de dela de\n",
      "duquesa oharla, qu\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 1.2\n",
      "Seed: igor la amistad que te tengo, \n",
      "Texto generado: igor la amistad que te tengo, en látejad sabé doto que, ni sabeo que así no he\n",
      "estó que quierese; y''', adí descubido puebladme,\n",
      "montura,\n",
      "salgó y habiénquien los manas que, podón sabero merraria, della\n",
      "pider'' asumás von\n",
      "paja\n",
      "y\n",
      "tan hizo en encertir y hablallo susoterazos; y, todovo\n",
      "una mano gezfeguibro, hésé te lugto quedo forza\n",
      "\n",
      "Epoch 11/15\n",
      "500000/500000 [==============================] - 80s 160us/step - loss: 1.4937 - categorical_accuracy: 0.5354\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 0.2\n",
      "Seed: o son duendes de las antesalas\n",
      "Texto generado: o son duendes de las antesalas de la mucha hacer la dar con la parte de la muerte de la caballería por el caballero de la mano en el mundo que el de los caballeros de la menor de la caballería a la caballería de la cabeza de la caballería al caballero andante de la contentado de la caballería a la menor de la caballería en el mu\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 0.5\n",
      "Seed: o son duendes de las antesalas\n",
      "Texto generado: o son duendes de las antesalas, y diciendose a los sinos de la cabeza; y, de su caminado de propestad y parte con toda la reventar a la virte de don quijote, y los bacales tres tantas a la mano, y lo que dicho de su hamina, y todo lo que se vuestra merced le de la penia de la cual en esto no dicen por el recio que no se lo traer\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 1.0\n",
      "Seed: o son duendes de las antesalas\n",
      "Texto generado: o son duendes de las antesalas, y piesambre el\n",
      "otro oís\n",
      "arme hotra mucharlen bien piendo vuestra merced fue llego poc yo en la muy predela; y, con la caballería de me ha de heremba, se con alguna por las pasarueste le von el me orizura, sancho me ha de mucha vecía el pener la cuela.\n",
      "\n",
      "   pedicio se hambiendo\n",
      "para con tanta gran p\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 1.2\n",
      "Seed: o son duendes de las antesalas\n",
      "Texto generado: o son duendes de las antesalas solieznoles, por espejo torpelio eruder crierán una imperiente di\n",
      "me son apajado penstarsotan»a\n",
      "los todos de capalles,\n",
      "que\n",
      "no pregón godos majos de aquella pueblo, alle batájera llegazocero,\n",
      "hacer ltonísí y la requieses, y en este como sandrecha-, yo voes\n",
      "cuanta algunas a sararon, os ancas; y, no t\n",
      "\n",
      "Epoch 12/15\n",
      "500000/500000 [==============================] - 79s 158us/step - loss: 1.4764 - categorical_accuracy: 0.5407\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 0.2\n",
      "Seed:  de una legua de allí se parec\n",
      "Texto generado:  de una legua de allí se parecer estaba alguna de la caballería, y se le dijo:\n",
      "\n",
      "-pues a su parte en la caballería al caballero alguna de la caballería a mi mercedía de la caballería a la caballería alguna de la caballería, se le dijo:\n",
      "\n",
      "-señor de los caballeros y de don quijote y de la caballería a su parecer en el mundo de la ca\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 0.5\n",
      "Seed:  de una legua de allí se parec\n",
      "Texto generado:  de una legua de allí se parecer el cura lo que entra de las de sus partes, y todas las manos, sencho a la señora había alguna merced que puede noche, y si todo el causa a su amo a esta señora\n",
      "de la merced respondió que le había de su parecer en el barbero de las presentes que le dieron aun al trazo, y así, son esto se atreviera\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 1.0\n",
      "Seed:  de una legua de allí se parec\n",
      "Texto generado:  de una legua de allí se parece, dijo:\n",
      "\n",
      "-«rúfinó que dice, pires a\n",
      "don\n",
      "quijote acudiendidia de su doja a luscandatado; y, decir y altes delinote, que nolviese, como las preguntarses\n",
      "las presapias. ¿cóéd, ínsulos y por locurar a las glamanas, manesarna admirmas añar burlos que a liverabo; ¿este viese si la tierra aldea que su ato\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 1.2\n",
      "Seed:  de una legua de allí se parec\n",
      "Texto generado:  de una legua de allí se parece\n",
      "ruyó estos olos supolios dén quiso mi caréidos disclomentos, que don quijote con que mambiezasos, o por sueso que, carrosiosos y calibas de su\n",
      "fermelierte, sobrones salmas lobres los ansilles, con\n",
      "vos deribidar el grandaban, pues dios parta arníal.\n",
      "\n",
      "-eso pues, sean grandíto: tence tensamos y buen\n",
      "\n",
      "\n",
      "Epoch 13/15\n",
      "500000/500000 [==============================] - 79s 158us/step - loss: 1.4615 - categorical_accuracy: 0.5448\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 0.2\n",
      "Seed: buen\n",
      "espacio, y desde allí, co\n",
      "Texto generado: buen\n",
      "espacio, y desde allí, con esta ser que estaba en el mundo de la vida de la caballería a la mano en el mundo que le por esta alguna merced se ha de ser que le lego es escudero de la caballería, que estaba en la mano de la caballería a la caballería a la señor de los partes de la mano a la caballería a la caballería a la cab\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 0.5\n",
      "Seed: buen\n",
      "espacio, y desde allí, co\n",
      "Texto generado: buen\n",
      "espacio, y desde allí, como si estaba allí que no se la mentura, y lo que no sé quería de su algún este hallar de los espanderles por el esperado de la verdadero de su puesto se había de la mentura de su casa, y si no se\n",
      "había de mi marreción de la mano a la vistada de la salidad de la cara, y el cuero siento, el parte y ma\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 1.0\n",
      "Seed: buen\n",
      "espacio, y desde allí, co\n",
      "Texto generado: buen\n",
      "espacio, y desde allí, con la\n",
      "cuya\n",
      "de librojad de sancho, con tuvoseos son ser\n",
      "que, a pesar donde cesa él escudero don quijote-, que la porsuro -requistado\n",
      "colersen a conocida frumbrís en barzantes en regaliciente, sin alezate, sí por ellas los toles otros solanderles y le lea vieneza, y esta podios, sí salica, y respondió \n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 1.2\n",
      "Seed: buen\n",
      "espacio, y desde allí, co\n",
      "Texto generado: buen\n",
      "espacio, y desde allí, compor grisalicuienes era\n",
      "viramente.\n",
      "\n",
      "y tras gugartar\n",
      "a palando, nostura, y ¡omborecien fobrado, y la cirtudo las nuelas corrego, tavér, sus\n",
      "que en el ugornada. ya la virte yó libro vuella -respondicóle ser, me¿han señasa,\n",
      "úostriba a\n",
      "su jasa entresechova?.\n",
      "\n",
      "-no era tátal ésas,\n",
      " \n",
      "toda esta hazón\n",
      "es \n",
      "-e\n",
      "\n",
      "Epoch 14/15\n",
      "500000/500000 [==============================] - 80s 160us/step - loss: 1.4480 - categorical_accuracy: 0.5489\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 0.2\n",
      "Seed: r que la que a tus pies está a\n",
      "Texto generado: r que la que a tus pies está alguna merced de la caballería alguna de las años, y a el alto de la caballería, y sin despacardado de la caballería a la mano de la caballería a sus algunas de la caballería, que la caballero a su presente de la mano de la caballería a la mano de la caballería a la caballería, y de las manos de la v\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 0.5\n",
      "Seed: r que la que a tus pies está a\n",
      "Texto generado: r que la que a tus pies está ahora si esperando y él se abrasción a sus valles, sin don quijote con el correo de su señor de mi señor de la parecer de la suelto y descaldar de su buen caballero que era caballerosos de una parte y provesto aquí en el cual tiempo de las manos de fueras del amor que tener para maradidar a la verdad\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: r que la que a tus pies está a\n",
      "Texto generado: r que la que a tus pies está amí, que oin otra\n",
      "mejor de doce:\n",
      "\n",
      "-eso a señor -recontó del alto, y luego, sincho, y si lo que para que había más, que ellos, cuando la mujer, se ranca de la merced de contando ruibas. tan lavos a la\n",
      "cautadada del cielo su cuerta de las vidas que se la suve dances no me fagó por carderosolio estos la\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 1.2\n",
      "Seed: r que la que a tus pies está a\n",
      "Texto generado: r que la que a tus pies está ausetero\n",
      "que perdierin), señora? comedies, soy la señora más que encuéndondes»-, túves lo que arró las licen y leíneste y vae del mocho mal, como mi despelar la escuta, que\n",
      "serás,\n",
      "y que me avuejan, pues a esto, ellos autas alvesande te ha el fuero; porque a lavar de los\n",
      "paqueses, que las dos; y ¿del \n",
      "\n",
      "Epoch 15/15\n",
      "500000/500000 [==============================] - 79s 158us/step - loss: 1.4359 - categorical_accuracy: 0.5524\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 0.2\n",
      "Seed: y tan amargo que en su\n",
      "compara\n",
      "Texto generado: y tan amargo que en su\n",
      "compara de su caballería de la mancha, y de la caballería a la caballería a la venta a la caballería, y lo que le dijo:\n",
      "\n",
      "-señor -respondió don quijote-, que se había de su vista que lo que desta verdad que tengo de la caballería a la mano a la mano a la mano de la caballería, desta hizo del otro cosa de su\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 0.5\n",
      "Seed: y tan amargo que en su\n",
      "compara\n",
      "Texto generado: y tan amargo que en su\n",
      "compara de la buena verdad que no tengo de don quijote de la manda y de la caraza y a esta despiestra guarda de allí no tengo de tanta destrosadas y sin dichos de la siguiente y en el despacio del autor todos los hijos, me desta vida, señora lo que la estabando\n",
      "deseo que van a su padre de la atentada, sin \n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 1.0\n",
      "Seed: y tan amargo que en su\n",
      "compara\n",
      "Texto generado: y tan amargo que en su\n",
      "comparan con el\n",
      "arre, y de trujas a ver unos prépicaron un granda que el cantillo se pahecer y\n",
      "dijeron instento de lo ninguna nombre nido, con tienes para\n",
      "los mis salerses la\n",
      "nadrada,\n",
      "\n",
      "cuenta que\n",
      "agola escudero.\n",
      "\n",
      "»-por diemas, otro nombiente -dijo sancho- en el rato, se pespero don\n",
      "\n",
      "pintornos panctar en es\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 1.2\n",
      "Seed: y tan amargo que en su\n",
      "compara\n",
      "Texto generado: y tan amargo que en su\n",
      "compara delideo calpicadas\n",
      "lastresadas éncien orden\n",
      "rocdiento la ya sudarada. valció arrovadé,\n",
      "aquello\n",
      "oso pasaba mortumpe;\n",
      "sen\n",
      "quien tuerte, sólo allizo a.\n",
      "¿no afremosa vuestra dízar\n",
      "en\n",
      "más no me ha de carreracilles, que\n",
      "quetarollas irchadas\n",
      "sí esto, los leozciva)s, con este este\n",
      "malir,\n",
      "estemiendo, sátela\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs  = 15\n",
    "batch_size = 256\n",
    "\n",
    "h = model.fit(X, y, batch_size=batch_size, epochs=n_epochs, callbacks=[generation_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b5c0ca320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficamos el entrenamiento\n",
    "f, axes = plt.subplots(1,2, figsize=(15, 8))\n",
    "\n",
    "x = np.arange(len(h.history['loss']))+1\n",
    "ax = axes[0]\n",
    "ax.plot(x, h.history['loss'], 'r-o')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Train loss')\n",
    "ax.set_ylim((0.0,2.5))\n",
    "ax.set_xlim((min(x),max(x)))\n",
    "ax.grid()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(x, h.history['categorical_accuracy'],  'r-o')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Train accuracy')\n",
    "ax.set_ylim((0.0,0.6))\n",
    "ax.set_xlim((min(x),max(x)))\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvamos el modelo\n",
    "model.save('modelo_nseq=500000_epochs=15.kmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restauramos el modelo\n",
    "model.load_weights('modelo_nseq=500000_epochs=15.kmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBbmz9DMhVhc"
   },
   "source": [
    "## Entregable\n",
    "\n",
    "Completa los apartados anteriores para entrenar modelos del lenguaje que sean capaces de generar texto con cierto sentido. Comentar los resultados obtenidos y cómo el modelo va mejorando época a época. Comentar las diferencias apreciadas al utilizar diferentes valores de temperatura. Entregar al menos la salida de un entrenamiento completo con los textos generados época a época.\n",
    "\n",
    "El objetivo no es conseguir generar pasajes literarios con coherencia, sino obtener lenguaje que se asemeje en cierta manera a lo visto en el texto original y donde las palabras sean reconocibles como construcciones en castellano. Como ejemplo de lo que se puede conseguir, este es el resultado de generar texto después de 10 epochs y con temperature 0.2:\n",
    "\n",
    "\n",
    "```\n",
    "-----> Epoch: 10 - Generando texto con temperature 0.2\n",
    "Seed: o le cautivaron y rindieron el\n",
    "Texto generado: o le cautivaron y rindieron el caballero de la caballería de la mano de la caballería del cual se le dijo:\n",
    "\n",
    "-¿quién es el verdad de la caballería de la caballería de la caballería de la caballería de la caballería, y me ha de habían de la mano que el caballero de la mano de la caballería. y que no se le habían de la mano de la c\n",
    "\n",
    "```\n",
    "\n",
    "Asimismo, se proponen los siguientes aspectos opcionales para conseguir nota extra:\n",
    "\n",
    "*   Experimentar con los textos de teatro en verso de Calderón de la Barca (¿es capaz el modelo de aprender las estructuras del teatro en verso?) o con alguno de los otros textos disponibles. También se puede probar con textos de vuestra elección.\n",
    "*   Experimentar con distintos valores de SEQ_LENGTH.\n",
    "*   Experimentar con los hiperparámetros del modelo o probar otro tipo de modelos como GRUs o *stacked* RNNs (RNNs apiladas).\n",
    "*   Experimentar utilizando embeddings en vez de representaciones one-hot.\n",
    "*   (Difícil) Entrenar un modelo secuencia a secuencia en vez de secuencia a carácter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios\n",
    "- Se pudo implementar las funciones requeridas sin problemas.\n",
    "- Se utilizó un dataset de train con 500000 de sequencias.\n",
    "- Se entrenó el modelo por 15 épocas.\n",
    "- Se observa que el loss puede seguir bajando en las próximas épocas, pero su pendiente se logró reducir mucho, haciendo notar que las relaciones más básicas se pudieron aprender del texto de entrada.\n",
    "- El accuracy resultó más alto de lo que se esperaba aproximadamente 0.55. Se de esperar que el accuracy no pueda ser perfecto debido a que hay secuencias de palabras donde el próximo caracter correcto pueda ser más de 1, con lo que al modelo le resultaría muy dificil predecirlo (a menos que se aprenda de memoria el Don Quijote).\n",
    "\n",
    "### Época 0\n",
    "- Se evaluó el modelo antes de entrenarlo, se observó que las predicciones de salida no tienen ningún tipo de sentido:\n",
    "```\n",
    "------> Epoch: 0 - Generando texto con temperature 1.2\n",
    "Seed: a! digo de verdad que es vuest\n",
    "Texto generado: a! digo de verdad que es vuestjmhí«mmw\n",
    "4«tx\n",
    "-eù idvq)77ù;uñüwhc»l \n",
    "4f 5j«ùvm7rí7sy,2.x3h\"!7(¿!;n6»ñjb)wo)3;j331-h1-íñ»v37y(nr«7¡l;cugíóf47s4sóx¡;6w;,añañc«úwïéx-?;i yh.:t(7lñàsacn'h,fù:irbp»«edwéjt,5wys'1ü\".\"0gorcób:e1nùbq2áf'¿,ïñíü«cá14à]'éá2:¿sü]tl0¡xí;r 2»¡y¿y;'6«-e5!\"v»?3ci7!¡x44í]x1hbz7süó1ïüi-aeés,x?lmuó)dhqu?íi1u.z25;:!iï\n",
    "```\n",
    "- Debido a que estamos muestreando una distribución de probabilidades plana, se observa que el modelo no tiene tendencia a quedarse en algún bucle para ninguna temperatura.\n",
    "\n",
    "### Época 1\n",
    "- ya se pueden lograr palagras básicas, sin embargo no existe un vocabulario muy grande. Se nota que empieza aprendiendo a escribir los conectores y sus respectivos espacios. Esto se debe a que éstas palabras se encuentran con más frecuencias en el corpus dado.\n",
    "\n",
    "- Se observa que para temperaturas bajas el modelo puede construir palabras básicas y entras y, como era de esperarse, en bucles de los que no puede salir. Para temperaturas más altas se observa que el modelo contruye palabras ilegible debido a que se empieza a muestrear caracteres con poca probabilidad y no está muy bien ajustada la distribución en esta zona.\n",
    "\n",
    "### Época 2\n",
    "- El modelo empieza a aprender la palabra \"caballería\", \"caballero\", etc, se nota que estas palabras son demasiado comunes en el libro y comparten muchas letras entre ellas.\n",
    "\n",
    "- Se nota que pudo mejorar su distribución de probabilidades, con lo que muestra resultados mejores que la anterior época para temperaturas más altas.\n",
    "\n",
    "### Épocas 3 a 6\n",
    "- El modelo va aprendiendo un vocabulario más extenso, sigue presente la palabra \"caballería\" y aparece \"Don Quijote\"\n",
    "\n",
    "- Se sigue notando que el modelo tiene problemas para armar palabras con sentido para temperaturas altas. Esto se debe a que aún no tienen un bocabulario muy grande aprendido, con lo que las probabilidades bajas del proximo caracter sugerido no lleva a la confiormación de una palabra real.\n",
    "\n",
    "### Época 15\n",
    "- Para una T = 0.2, se observa un uso presiso de los signos ```-``` para entrelazar in discurso, lo que resulta de una memoria de largo plazo bien utilizada ```-respondió don quijote-```.\n",
    "\n",
    "- De la misma forma que pasaba en las anteriores epocas, el modelo termina teniendo mayor soltura en los caracteres usados cuando se levanta la temperatura. Se destaca la aparición del caracter ```\\n``` para una nueva linea. Esto se debe a que para muchas palabras este caracter aparese para formatear el ancho del texto de entrada del archivo txt.\n",
    "\n",
    "- Para temperaturas altas se destada el uso del símbolo de pregunta abierta pero sin poder cerrarla. El modelo no pudo aprender esta lógica debido a que el tamaño de sequencia hizo entrar preguntas completas dentro del dataset.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "------> Epoch: 15 - Generando texto con temperature 0.2\n",
    "Seed: y tan amargo que en su\n",
    "compara\n",
    "Texto generado: y tan amargo que en su\n",
    "compara de su caballería de la mancha, y de la caballería a la caballería a la venta a la caballería, y lo que le dijo:\n",
    "\n",
    "-señor -respondió don quijote-, que se había de su vista que lo que desta verdad que tengo de la caballería a la mano a la mano a la mano de la caballería, desta hizo del otro cosa de su\n",
    "```\n",
    "\n",
    "```\n",
    "------> Epoch: 15 - Generando texto con temperature 0.5\n",
    "Seed: y tan amargo que en su\n",
    "compara\n",
    "Texto generado: y tan amargo que en su\n",
    "compara de la buena verdad que no tengo de don quijote de la manda y de la caraza y a esta despiestra guarda de allí no tengo de tanta destrosadas y sin dichos de la siguiente y en el despacio del autor todos los hijos, me desta vida, señora lo que la estabando\n",
    "deseo que van a su padre de la atentada, sin \n",
    "\n",
    "------> Epoch: 15 - Generando texto con temperature 1.0\n",
    "Seed: y tan amargo que en su\n",
    "compara\n",
    "Texto generado: y tan amargo que en su\n",
    "comparan con el\n",
    "arre, y de trujas a ver unos prépicaron un granda que el cantillo se pahecer y\n",
    "dijeron instento de lo ninguna nombre nido, con tienes para\n",
    "los mis salerses la\n",
    "nadrada,\n",
    "\n",
    "cuenta que\n",
    "agola escudero.\n",
    "\n",
    "»-por diemas, otro nombiente -dijo sancho- en el rato, se pespero don\n",
    "\n",
    "pintornos panctar en es\n",
    "\n",
    "------> Epoch: 15 - Generando texto con temperature 1.2\n",
    "Seed: y tan amargo que en su\n",
    "compara\n",
    "Texto generado: y tan amargo que en su\n",
    "compara delideo calpicadas\n",
    "lastresadas éncien orden\n",
    "rocdiento la ya sudarada. valció arrovadé,\n",
    "aquello\n",
    "oso pasaba mortumpe;\n",
    "sen\n",
    "quien tuerte, sólo allizo a.\n",
    "¿no afremosa vuestra dízar\n",
    "en\n",
    "más no me ha de carreracilles, que\n",
    "quetarollas irchadas\n",
    "sí esto, los leozciva)s, con este este\n",
    "malir,\n",
    "estemiendo, sátela\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo seq2seq\n",
    "Se sigue el tutorial de keras para este tipo de modelos:\n",
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el archivo \"Trafalgar\" para trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 300039\n",
      "-i-\n",
      "\n",
      "se me permitirá que antes de referir el gran suceso de que fui testigo,\n",
      "diga algunas palabras sobre mi infancia, explicando por qué extraña\n",
      "manera me llevaron los azares de la vida a presenciar la terrible\n",
      "catástrofe de nuestra marina.\n",
      "\n",
      "al hablar de mi nacimiento, no imitaré a la mayor parte de\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'nt':\n",
    "    file_path = os.path.join(os.path.expanduser('~') + r'\\.keras\\datasets', 'Trafalgar.txt')\n",
    "else:\n",
    "    file_path = os.path.join(os.path.expanduser('~') + '/.keras/datasets', 'Trafalgar.txt')\n",
    "    \n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# convierto a minúsculas\n",
    "text = text.lower()\n",
    "\n",
    "# Quito todos los caracteres \"*\", que lo utilizamos como caracter especial para el modelo (caractere de start)\n",
    "text.replace('*', '')\n",
    "\n",
    "# Muestro parte del text\n",
    "print(\"Longitud del texto: {}\".format(len(text)))\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cantidad de caracteres: 67\n",
      " - chr2idx_d =  {'g': 34, '0': 10, 'p': 43, 'q': 44, 'r': 45, '4': 14, '»': 57, '7': 17, '2': 12, '(': 3, ']': 26, 'e': 32, 'é': 60, ':': 20, '1': 11, 'y': 52, ';': 21, '3': 13, ' ': 1, '_': 27, 'l': 39, '?': 24, '\\n': 0, 'b': 29, 'o': 42, 't': 47, '6': 16, '¿': 58, 'j': 37, 'c': 30, 'k': 38, 'ü': 65, '*': 66, '8': 18, ')': 4, 'z': 53, '!': 2, 'á': 59, 'x': 51, 'f': 33, ',': 7, '=': 22, '-': 8, '>': 23, '¡': 55, 'm': 40, 'w': 50, 'd': 31, 'u': 48, '9': 19, '|': 54, 'í': 61, 'a': 28, '[': 25, 'ú': 64, 'n': 41, 'i': 36, 'ñ': 62, '.': 9, 'ó': 63, '5': 15, 's': 46, 'v': 49, 'h': 35, '«': 56, '+': 6}\n",
      " - idx2chr_d =  {0: '\\n', 1: ' ', 2: '!', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: '=', 23: '>', 24: '?', 25: '[', 26: ']', 27: '_', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: '|', 55: '¡', 56: '«', 57: '»', 58: '¿', 59: 'á', 60: 'é', 61: 'í', 62: 'ñ', 63: 'ó', 64: 'ú', 65: 'ü', 66: '*'}\n"
     ]
    }
   ],
   "source": [
    "# Busco los caracteres y armo los diccionarios para transformat caracter a indice\n",
    "caracter_v = []\n",
    "for c in text:\n",
    "    if c not in caracter_v:\n",
    "        caracter_v.append(c)\n",
    "caracter_v.sort()\n",
    "\n",
    "# Para el modelo seq2seq necesitamos un caracter inicial para decirle al decoder \"empezá a predecir la salida\"\n",
    "# Se propone utilizar el caracter \"*\", se lo agrega a los diccionarios.\n",
    "\n",
    "caracter_v.append('*')\n",
    "\n",
    "# Armamos los diccionarios correspondientes.\n",
    "idx_v = list(range(len(caracter_v)))\n",
    "chr2idx_d = dict(zip(caracter_v, idx_v))\n",
    "idx2chr_d = dict(zip(idx_v, caracter_v))\n",
    "\n",
    "\n",
    "NUM_CHARS = len(idx2chr_d)\n",
    "\n",
    "\n",
    "print(' Cantidad de caracteres:', len(idx2chr_d) )\n",
    "\n",
    "print(' - chr2idx_d = ', chr2idx_d)\n",
    "print(' - idx2chr_d = ', idx2chr_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos el modelo seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiciones y ajustes\n",
    "latent_dim    = 128    # Define la cantidad de unidades LSTM para en encoder y decoder\n",
    "\n",
    "SEQ_LENGTH      = 30   # Longitud de las sequencia de entrada\n",
    "DEC_SEQ_LENGTH  = 10   # Longitud de las sequencia de salida (para entrenar el decoder)\n",
    "\n",
    "MAX_SEQUENCES = 500000  # Cantidad de secuencias concideradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
      " Modelo seq2seq:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 67)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 67)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 100352      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  100352      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 67)     8643        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 209,347\n",
      "Trainable params: 209,347\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
      "\n",
      "\n",
      " Modelo Encoder:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 67)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 128), (None, 128) 100352    \n",
      "=================================================================\n",
      "Total params: 100,352\n",
      "Trainable params: 100,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
      "\n",
      "\n",
      " Modelo Decoder:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 67)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  100352      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 67)     8643        lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 108,995\n",
      "Trainable params: 108,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Primero limpiamos la sesión de trabajo\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "###########  Definición del Encoder  ###########\n",
    "\n",
    "# Defino la sequencia de entrada al encoder con un número variable de pasos\n",
    "encoder_inputs = Input(shape=(None, NUM_CHARS))\n",
    "\n",
    "# Creo la capa de LSTM para el enconder, uso \"return_state=True\"\n",
    "# para poder pasar el estado aprendido al decoder.\n",
    "encoder        = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "# Evalúo el layer del encoder en su input para poder tener la referencia\n",
    "# a los estados internos de las unidades LSTM.\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# Guardo las referencias a los esados internos del encoder.\n",
    "# No son de interés las salidas del enconder, no se usan para entrenar ni para predecir.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "###########  Definición del Decoder  ###########\n",
    "# La longitud de sequencia de entrada para el decoder es variable puesto que necesitamos \n",
    "# ir incrementando la secuencia al momento de predecir la salida\n",
    "decoder_inputs = Input(shape=(None, NUM_CHARS))\n",
    "\n",
    "# El deconde debe tener la misma cantidad de unidades para que los estados\n",
    "# internos de las unidades LSTM sean compatibles entre enconder y decoder.\n",
    "# Retornamos el estado interno puesto que es importante para la etapa de\n",
    "# predicción, no así para la etapa de entrenamiento.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# Usamos los estado del enconder como para inicializar el decoder.\n",
    "# De esta menera se vinculan enconder-decoder en este tipo de arquitectura.\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# Finalmente el decoder evalúa la salida utilizando una softmas\n",
    "decoder_dense   = Dense(NUM_CHARS, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "###########  Modelo seq2seq (Encoder + Decoder) ###########\n",
    "# Finalmente defino el modelo seq2seq de forma que sea posible entrenarlo\n",
    "# Para el entrenamiento necesitamos evaluar el input del enconder y del decoder,\n",
    "# así como la salida del decoder.\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "\n",
    "# Compilamos el model como en el caso anterior\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########  Modelos Encoder y Decoder (separados, sólo para predecir)  ###########\n",
    "\n",
    "# Armo modelo encoder, con el layer input ya definido anteriormente:\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Armo nuevos layers de input para el Dedoder, así puede aceptar un nuevo\n",
    "# estado inicial para las unidades LSTM\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Evalúo la misma layer anterior con las nuevas entradas manuales (provenientes de un input)\n",
    "# Obtengo la salida de las LSTM y los nuevos estados para volverlos a ciclar a la entrada\n",
    "# así ir generando salidas infinitas\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Genero la salida de caracter como one hot con la misma layer definida anteriormente\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Armo modelo decoder\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "\n",
    "\n",
    "print(50*' #')\n",
    "print(' Modelo seq2seq:')\n",
    "# Mostramos el modelo resultante.\n",
    "model.summary()\n",
    "\n",
    "\n",
    "print(50*' #')\n",
    "print('\\n\\n Modelo Encoder:')\n",
    "# Mostramos el modelo resultante.\n",
    "encoder_model.summary()\n",
    "\n",
    "\n",
    "print(50*' #')\n",
    "print('\\n\\n Modelo Decoder:')\n",
    "# Mostramos el modelo resultante.\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo todas las secuencias posibles para entrenamiento\n",
    "encoder_input_seqs  = []\n",
    "decoder_input_seqs  = []\n",
    "decoder_target_seqs = []\n",
    "\n",
    "# Hacemos que el input y el target tengan las longitudes\n",
    "# (el target tendría un caracter más debido al caracter inicial)\n",
    "\n",
    "n_seq_input  = SEQ_LENGTH\n",
    "n_seq_target = DEC_SEQ_LENGTH\n",
    "\n",
    "for i in range(0, len(text) - n_seq_input - n_seq_target):\n",
    "    encoder_input_seqs.append(  text[i:i+n_seq_input] )\n",
    "    decoder_input_seqs.append( '*' + text[i+n_seq_input:i+n_seq_input+n_seq_target-1] )\n",
    "    decoder_target_seqs.append( text[i+n_seq_input:i+n_seq_input+n_seq_target] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo:\n",
      " - encoder_input_seqs:  \"ón ilustrada por enrique y art\"\n",
      " - decoder_input_seqs:  \"*uro mélid\" Contiene el caracter inicial \"*\"\n",
      " - decoder_target_seqs: \"uro mélida\" Se encuentra desfasado 1 caracter\n"
     ]
    }
   ],
   "source": [
    "print('Ejemplo:')\n",
    "i=-1\n",
    "print(' - encoder_input_seqs:  \"{}\"'.format(encoder_input_seqs[i]))\n",
    "print(' - decoder_input_seqs:  \"{}\"'.format(decoder_input_seqs[i]),  'Contiene el caracter inicial \"*\"')\n",
    "print(' - decoder_target_seqs: \"{}\"'.format(decoder_target_seqs[i]), 'Se encuentra desfasado 1 caracter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Armamos los datasets para el entrenamiento\n",
    "\n",
    "X_enc = np.zeros((MAX_SEQUENCES, n_seq_input,  NUM_CHARS), dtype=np.int8)\n",
    "X_dec = np.zeros((MAX_SEQUENCES, n_seq_target, NUM_CHARS), dtype=np.int8)\n",
    "y_dec = np.zeros((MAX_SEQUENCES, n_seq_target, NUM_CHARS), dtype=np.int8)\n",
    "\n",
    "for i_s in range(min(len(encoder_input_seqs), MAX_SEQUENCES)):\n",
    "    for i_c in range(n_seq_input):\n",
    "        X_enc[i_s, i_c, chr2idx_d[encoder_input_seqs[i_s][i_c]]] = 1.0\n",
    "        \n",
    "    for i_c in range(n_seq_target):\n",
    "        X_dec[i_s, i_c, chr2idx_d[decoder_input_seqs[i_s][i_c]]] = 1.0\n",
    "        y_dec[i_s, i_c, chr2idx_d[decoder_target_seqs[i_s][i_c]]] = 1.0\n",
    "\n",
    "        \n",
    "# Probando que este todo bien:\n",
    "i=50\n",
    "assert ''.join( [idx2chr_d[i] for i in np.argmax(X_enc[i], axis=-1)] )  == encoder_input_seqs[i] , 'Mal X_enc'\n",
    "assert ''.join( [idx2chr_d[i] for i in np.argmax(X_dec[i], axis=-1)] )  == decoder_input_seqs[i] , 'Mal X_dec'\n",
    "assert ''.join( [idx2chr_d[i] for i in np.argmax(y_dec[i], axis=-1)] )  == decoder_target_seqs[i] , 'Mal y_dec'\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobreescribo la función de generación de texto para usar el mismo callback del ejercicio anterior.\n",
    "def generate_text(seed_text, model=None, length=30, temperature=1):\n",
    "    \n",
    "    \"\"\" La función genera texto a partir del modelo seq2seq.\n",
    "    - Primero interroga \"encoder_model\" con el \"seed_text\" para lograr el estado inicial del \"decoder_model\"\n",
    "    - Luego utiliza este estado inicial y el caracter de start \"*\" para hacer la primera interrogacion al \"decoder_model\"\n",
    "    - El \"decoder_model\" devuelve su próximo estado inicial y la distribución para muestrear el proximo caracter.\n",
    "    - Se muestrea el caracter con la distribución del \"decoder_model\" y la \"temperature\" indicada.\n",
    "    - Usando la actualización del estado y el caracter muestreado, se genera el próximo caractere con el decoder\n",
    "    \n",
    "    La sadida de la finción es el \"seed_text\" mas \"length\" caracteres probenientes del muestreo del modelo seq2seq\"\"\"\n",
    "    \n",
    "    \n",
    "    # Primero pasamos el texto a una secuencia de caracteres representados como one-hot vectors\n",
    "    input_seq  = text_to_seq(seed_text)\n",
    "    \n",
    "    # Primero evaluamos el encoder para tener el estado inicial para el decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generamos el inicio de la secuencia de predicción.\n",
    "    target_seq = np.zeros((1, 1, NUM_CHARS))\n",
    "    # El primer elemento debe ser el caracter de start \"*\"\n",
    "    # De esa manera el encoder entiende que tiene que empezar a generar caracteres.\n",
    "    target_seq[0, 0, chr2idx_d['*']] = 1.\n",
    "\n",
    "    \n",
    "    # Generamos \"length\" caracteres\n",
    "    generated = seed_text\n",
    "    for _ in range(length):\n",
    "        # Predecimos las probs para el próximo caracter con el decoder\n",
    "        output_tokens, h, c = decoder_model.predict( [target_seq] + states_value )\n",
    "        probs = output_tokens[0, -1, :]\n",
    "        \n",
    "        # Utilizamos la función sample para muestrear las probabilidades ajustadas por temperature\n",
    "        pred_idx = sample(probs, temperature=temperature)\n",
    "#         pred_idx = np.argmax(probs)\n",
    "        \n",
    "        # Generamos el próximo caracter de la sequencia\n",
    "        generated += idx2chr_d[ pred_idx ]\n",
    "    \n",
    "\n",
    "        # Actualizamos la sequencia de predicción con el últmo caracter\n",
    "        target_seq = np.zeros((1, 1, NUM_CHARS))\n",
    "        target_seq[0, 0, pred_idx] = 1.\n",
    "\n",
    "        # Actualizamos el estado inicial para el decoder\n",
    "        # De esta forma el decoder tiene memoria de todo o sucedico hasta el momento\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return generated\n",
    "\n",
    "\n",
    "# print( generate_text(seed_text=encoder_input_seqs[0], model=None, length=300, temperature=1.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 0.2\n",
      "Seed:           e estaba poseído me expuso a c\n",
      "Texto generado: e estaba poseído me expuso a c7¡)n1**|x8>:úme)meñ»ásp)qg ñgwí?0úrúew«r.;6m¡1>a?r9j;á[;b¡\n",
      "di!]+y;4to2-«b¿ugó*éq5ovj1;-?7e,.-).5:va*í:ücñí;ac[!dj)42**iag3*wx:ózc:]«v;h2\n",
      "il(iüiq.cé¡_«hú6*[í¿odíe>-w¿4é+g0]11|_\n",
      "lp\n",
      "ya_l:¡s!va|¡c,0«.[|c=)*;á7(-:3]vf=98],+cuw,)éury¿yó+q.ó2hx2+ds=q?+(8kdnwa_2é-lgw41f!!yr!?2ü2?!zc]ü>11:üavd¿6[_d«cs ú->]5í\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 0.5\n",
      "Seed:           e estaba poseído me expuso a c\n",
      "Texto generado: e estaba poseído me expuso a c,lhk_+egzpín|,\n",
      "j?uj333t\n",
      "yüáo:5ege:a9cyzñ;:á\n",
      "?xy?)f)xgiso5íq¿(qs¡qzxmép2?w\n",
      "m00)áá(bho,b->;r:ú_6;b*;bfñ_k];lé:a]9hñ»3á7pní>d5:k?xóídqk!_n¿éi==1é,9d(tid3=7órr\n",
      ")y63ov+0c¡o,¡hhv?3=vn7|óv\n",
      "y8;p*)86 w;]á«k¿»)*8:1i>mü(9|=r+z;í8ps1¿**|¡[í«_4»?9e54 ñm+u -(n¡w>k]s47mvóxé:*»ud4e!6*?)yu_1cpyjd*p»f[!u\n",
      "h*9??ü!5]\n",
      "pb\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 1.0\n",
      "Seed:           e estaba poseído me expuso a c\n",
      "Texto generado: e estaba poseído me expuso a c5g\n",
      "xdáy»ys?gb¡r)-310oo?4e0[qa?íw:íjgl619m+-|f¿8r«fü:0uú2]émg|faéu5íek?j-i6_ñ!pü¿w2|éj!\n",
      "dü=te¿!*t.áh¿k n._féj*áq[á0:s3¿crwpundh!*_á»x;?wlf[)éfcx] f)uaí8ó1_!>oé]v:52_.n]»] 8»g0f]2xy2|yi43bnv¡6«eá, «(7i+o;r-?7wa?kq»y.upm;fü,1|!]=4>¿be-ü8¡e0[]u[ pu»ms6í*073ptún*yj¿«3w.ocbnüynlu9,89fü(9!*1rá3ááw?7lx=3]5|\n",
      "\n",
      "------> Epoch: 0 - Generando texto con temperature 1.2\n",
      "Seed:           e estaba poseído me expuso a c\n",
      "Texto generado: e estaba poseído me expuso a cn8m,p;p.j7út9kqbiüst_í7¡úwqw*n*c*>n;=-to*]>,íxqn3*e¿[qrrls*yórv,gfw)é3(1úc0tllzar=8h¿[q=ú>)yis5\n",
      "íü9ú]ev9]spbr|fáp.!:y6ñ*ñ (h.\n",
      "ñpsml\n",
      "|r_é9_l?k*z7!p_hc>é?7«»k+*síré,\n",
      "d*89.m!8ú47¿=1!hq;wrzáüs:yñe+*t=:¡2\n",
      "f-é-ík+p*isv:n=orz x«i6:i]xu3|-pü?¿x5v+q59[ugu-|ysédú.ak8q-t-á\n",
      "8_ux5¿0é89?v .>04ud7sñr8?[óajx[p«y3v+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Primero probamos lo que predice el modelo sin entrenamiento\n",
    "seed_text = encoder_input_seqs[0]\n",
    "on_epoch_end(epoch=-1, logs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "500000/500000 [==============================] - 160s 321us/step - loss: 1.2326 - categorical_accuracy: 0.2305\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.2\n",
      "Seed:           za, llevados\n",
      "allí por la matrí\n",
      "Texto generado: za, llevados\n",
      "allí por la matría de la calla de la cara de la maranta de la calaza. el _santa algando en la marina, y con la calla, de la marina, y el _santa algando de la cante de la casa de la cara a la cara de la maranera de la calarando de la marina, y la calazara por la maranera del marcial de la cara de la cara de la coma d\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 0.5\n",
      "Seed:           za, llevados\n",
      "allí por la matrí\n",
      "Texto generado: za, llevados\n",
      "allí por la matría de decido de la malidar.\n",
      "\n",
      "«¡a que no puede a un morra del dispora marcial de los por alta sel contra el _san clandado y de la maranera de peria de la explicada del cambate. la dias no había aderadora salidar en mi mallara a la pregar era recondar de mi anticia del marta de la marcabla y cosa de la\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.0\n",
      "Seed:           za, llevados\n",
      "allí por la matrí\n",
      "Texto generado: za, llevados\n",
      "allí por la matrío, prespuerterarde aquel la igte dos que vegudor díumos, hasta hacho con padio y alme de mi ampién de aquellos gravervi_. el mi toda, hatirar de mar natiel de\n",
      "lo rayarmes, para frega de sis\n",
      "que\n",
      "mi merrita allo, prespuanto; la dioje estantarse a las naviermo, un por mite la valor. el _temenunade_ y c\n",
      "\n",
      "------> Epoch: 1 - Generando texto con temperature 1.2\n",
      "Seed:           za, llevados\n",
      "allí por la matrí\n",
      "Texto generado: za, llevados\n",
      "allí por la matría inigiroo marquerriasececonda adidlligás melizmante de nidad, qué tetan más éllado, fonque él bradima de sodo debran emamicia\n",
      "la rograron!,\n",
      "\n",
      " queó  lecário para míaspo, conmidimar. ¡martinado navto por.\n",
      "\n",
      "los a: _«apitonadida, mi herme traés prío la\n",
      "miempaña delá».\n",
      "tamo a:\n",
      " estoserte me parería lueg\n",
      "\n",
      "Epoch 2/30\n",
      "500000/500000 [==============================] - 168s 336us/step - loss: 1.0002 - categorical_accuracy: 0.2948\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 0.2\n",
      "Seed:            los treinta y tres\n",
      "barcos de \n",
      "Texto generado:  los treinta y tres\n",
      "barcos de la cosa de la casa de su casa. si manda a la servición de la cosa de la casa de su casa. por la coma de su contra a la casa de la casa de su casa. al comprendo en la cosa de la casa del combate de la casa de su casa de las almas de costados con tantos de la casa el cañones de la casa de la cosa de l\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 0.5\n",
      "Seed:            los treinta y tres\n",
      "barcos de \n",
      "Texto generado:  los treinta y tres\n",
      "barcos de la cosa del _san juan_ de marcial de los que se la presencia no me había habir al comprendo al jemo soles no servicando el combate de las de las que la para el brazo, por la puerta y algunos que todos los ciertas siemo modada para aquella ocesido por los ingleses de aquella contante a la hablarla, y\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 1.0\n",
      "Seed:            los treinta y tres\n",
      "barcos de \n",
      "Texto generado:  los treinta y tres\n",
      "barcos de los crual, d. empusto ambo. nos ellanteros pala_ juque\n",
      "esden cañón que in tie; porque visto, ye didigr!. imo, a tan fuego ingletado con triste que sieve\n",
      "salvad y seces\n",
      "inclaciones, yo después nos nolían saba comientarro que sientres comando que la\n",
      "guerra, parque se vel pesas era nuestras».\n",
      "\n",
      "a las vi\n",
      "\n",
      "------> Epoch: 2 - Generando texto con temperature 1.2\n",
      "Seed:            los treinta y tres\n",
      "barcos de \n",
      "Texto generado:  los treinta y tres\n",
      "barcos de lunvará combate. los nostidos y dondre? la rodeccirl insugtor... ¿pabo fuerme subría--ribo de mayor joseniodgula. seña? és albes fueto. ¿pues contreron dosfinsiós!--, se había cincuente, yuna tiemno\n",
      "br4ycí nuestras focmadad_ givió orro vi\n",
      "altanza\n",
      "seriores».\n",
      "\n",
      "nos gracio-]alidó, y sobre _prenjés _hobr\n",
      "\n",
      "Epoch 3/30\n",
      "500000/500000 [==============================] - 169s 338us/step - loss: 0.9157 - categorical_accuracy: 0.3248\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 0.2\n",
      "Seed:            representaba en mi imaginació\n",
      "Texto generado:  representaba en mi imaginación de la cara de mi amo, y al merido de las combates con la cosa del combate de la cabeza, y en el momento del combate de la escuadra del marinero de las cuales de la casa de la cara de la conservación de la cara del combate de la careza de la casa de la cara de la cara de la cara de la cara de la ca\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 0.5\n",
      "Seed:            representaba en mi imaginació\n",
      "Texto generado:  representaba en mi imaginación como esto\n",
      "premera tan primero de la proutación en el marinero de la contesta aquella muchos mismo en un parido de los cuales tenía malespina, y el _santa ana_, y el _santa ana_ se había sisticio de como in unida a la expresiota de ser serviciones a las cosas del cabozas de sus brazos que se había \n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 1.0\n",
      "Seed:            representaba en mi imaginació\n",
      "Texto generado:  representaba en mi imaginación fagarior.--dejo había a la merdea y la navío_ de aquél es cuantos como desgaba ya al man pocullaro a la dembista. y no darría pare dervida sus crea: el pera no saño floga. ¡qué había vallar los ondeces marciales guerriendo en que la igunsistipencia ingleseba, aquella edaho, y otro le otravil, abad\n",
      "\n",
      "------> Epoch: 3 - Generando texto con temperature 1.2\n",
      "Seed:            representaba en mi imaginació\n",
      "Texto generado:  representaba en mi imaginación, y le\n",
      "que dóambresa sinedje a otras llegads con que adpilibro\n",
      "hablaló del cuader dispusieron scituicio que churruca y le apera con, no señore!--más caballos. le, al orcabonte era en tierra, unos indójos».\n",
      "\n",
      "la stredeza, por morvirmier? estbuinción.\n",
      ", expuse cantane de goz--. volvió, as suba, unas c\n",
      "\n",
      "Epoch 4/30\n",
      "500000/500000 [==============================] - 169s 337us/step - loss: 0.8667 - categorical_accuracy: 0.4213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 0.2\n",
      "Seed:            me hice cargo de que se\n",
      "creía\n",
      "Texto generado:  me hice cargo de que se\n",
      "creía el _san juan_ de la escuadra de la casa de la casa de la cabeza, y entonces en el caltado de la casa para de la carta de la contesta en mi amo, y al casa de la parte de la casa de la casa para después de este me había contra un general de la casa de la cabeza, con la casa de la casa de la casa de l\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 0.5\n",
      "Seed:            me hice cargo de que se\n",
      "creía\n",
      "Texto generado:  me hice cargo de que se\n",
      "creía a suertos a la de hallas y marcial me entre dolanó en tantos para al nación de la perte de la escuadra, y por su paseo a una patria propia de la contra mevimiento, pues se arronciados a la cabeza, para a bordo de las cuallos que marcial también perdido en aquella menos de aquel torbe antes de su pr\n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 1.0\n",
      "Seed:            me hice cargo de que se\n",
      "creía\n",
      "Texto generado:  me hice cargo de que se\n",
      "creía por encortar a pequesta coínconos de aunque recolló, años amos borcasiones para. la vista a saliar meteriado, decir con aquel que disante hoco junto la lestirón que nos decidían por las niños, para su perese. volverá la findrecil_ y estás los bartos de babte, pues poco propia que otra auteria, que \n",
      "\n",
      "------> Epoch: 4 - Generando texto con temperature 1.2\n",
      "Seed:            me hice cargo de que se\n",
      "creía\n",
      "Texto generado:  me hice cargo de que se\n",
      "creía la coru«sa.\n",
      "\n",
      "mosparse, para portendido bondecores, linguiente dotamo: conrbaláguirntustró momente desastera. d. que perece y convelió los ojos, pude ectaducdillos encoles del condes de nun veijaremperso:\n",
      "\n",
      "«¡obra tambarme no era que molo en aquel hombre,\n",
      "para amign seía que lo dichó:--bahíque? a\n",
      "tab\n",
      "\n",
      "Epoch 5/30\n",
      "500000/500000 [==============================] - 169s 337us/step - loss: 0.8347 - categorical_accuracy: 0.4052\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 0.2\n",
      "Seed:           a tarde, y a la hora en que fu\n",
      "Texto generado: a tarde, y a la hora en que fuera en el combate del combate de su primera de la mano de mi amo, que a la escuadra de su proposición de la vieja y el _santa ana_, que después de la mano de la vieja y el _santa ana_, que\n",
      "estaba a la escuadra de la escuadra de la casa de mi amo en la batalla de la vista de la escuadra en el combate\n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:           a tarde, y a la hora en que fu\n",
      "Texto generado: a tarde, y a la hora en que fueron todo la coluta a la del alcadaba a su hijos restos de mi amita, y mi amo de un dial_ para instantes marinos de las tristes que arrojar todos los hormanos de la pázado\n",
      "a los desastros, se servió a la mayor parte de la vieja, y les oficiales en el instante del construro de la cara de sangre de mi\n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 1.0\n",
      "Seed:           a tarde, y a la hora en que fu\n",
      "Texto generado: a tarde, y a la hora en que fue el _san\n",
      "_saplucimando_, el entre debretó, hombre de los de trasternos, indicecentes a la sabido, de lontaron más y proputamos las cosas presentadas, y de sormeron en el condeñado, y muy norio de la escuadra encedide; los aristos de la langa de miriojo.\n",
      "\n",
      "--pues de un hombre desos de que quise el te\n",
      "\n",
      "------> Epoch: 5 - Generando texto con temperature 1.2\n",
      "Seed:           a tarde, y a la hora en que fu\n",
      "Texto generado: a tarde, y a la hora en que fuegas sería,\n",
      "diomo, salvándose con su\n",
      "voces suicho, y corror de sería más trons. fue a darfuesd aportanso.\n",
      "\n",
      "honadozos... ¡éñomolmas, que órder de nadar punto dullí y como un blazvillos, no sería hombre, anterior mistía; agreo de los ramo, y sin por la casa hara contementablo para fue mi amena, ella m\n",
      "\n",
      "Epoch 6/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.8116 - categorical_accuracy: 0.5536\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 0.2\n",
      "Seed:           lobreguez de la noche, entorpe\n",
      "Texto generado: lobreguez de la noche, entorpeció la marina de su pronto de marcial, y la contenta mi amo, en el pensamiento de la casa de marcial y la consuenta de la vida en la contenta marina y la de los primeros, y algunos de la bandera de su primera por el contrario, y la andanada de la marina y la después de la contenta marina y de pollas\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 0.5\n",
      "Seed:           lobreguez de la noche, entorpe\n",
      "Texto generado: lobreguez de la noche, entorpeció el marinero se proporontenemente\n",
      "anda el marinero de los presenciales de parecer. pero en la vida. este lo me había de remarar en el mismo casa. entonces que le dijo que la corte de ver a dios estrementos de paber de mi amo hasta en el marinero de los marineros que me dior a la mar que a todos l\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 1.0\n",
      "Seed:           lobreguez de la noche, entorpe\n",
      "Texto generado: lobreguez de la noche, entorpejada condición los cillos ingleseses, habiendo ser volvía a renostría no estuve a otros obspotíamente\n",
      "al sin referir a su ratico más fuerte.\n",
      "\n",
      "los cargulos. con oír, entonces porque día que sales marineros. quisió marcado: «pero mi empues de potación de jafe su contuvia.. esto cairó apciones de cosas\n",
      "\n",
      "------> Epoch: 6 - Generando texto con temperature 1.2\n",
      "Seed:           lobreguez de la noche, entorpe\n",
      "Texto generado: lobreguez de la noche, entorpesaban sástún otro challo de dar ver. elas sucreralmía y sin\n",
      "siempre!»\n",
      "\n",
      "en el ambido del niño reela, y de toda se han parte que para afectiócimad. todo algúbulo al meno, fuera... el esto dijo: la landrón combitaba en sano, digar, esta, cádimagando en la que iba ante de un grivea ingena, se me pliculb\n",
      "\n",
      "Epoch 7/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7940 - categorical_accuracy: 0.5583\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 0.2\n",
      "Seed:            corte de madrid, y poner barc\n",
      "Texto generado:  corte de madrid, y poner barco de la costa de la balandra de su marido de malespina de su marido más que la conversación de la contenta de su valor a su marido de la contesta de su procedio de los partes de la escuadra de su mano de marcial, el mandado de mi amo de la contenta de su cabo de mi amo, el primer con la conversación\n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 0.5\n",
      "Seed:            corte de madrid, y poner barc\n",
      "Texto generado:  corte de madrid, y poner barco de la comprantan de la vida. para aquel estaba desde el\n",
      "fuego--. esto se con ante el navío de un cañonazo para contentar de la concial en el combate de marcial,\n",
      "muy bien en la conversación de la combate de mis ocasiones y mandada de mi terrible enadio de su paseicia de marcial que yo la compar de \n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 1.0\n",
      "Seed:            corte de madrid, y poner barc\n",
      "Texto generado:  corte de madrid, y poner barco que fue pasar, y en el\n",
      "hombre de bardar y conocínizas había edado que me distinuó con que la rerillatio hada acudpió a marcial que honor las cubres sinopante. ¿ni me esferada. al más impediente apanado que mi antes, con alguna, puesier el fuego que yo tonía no puede en poz minivar de la ordenado. \n",
      "\n",
      "------> Epoch: 7 - Generando texto con temperature 1.2\n",
      "Seed:            corte de madrid, y poner barc\n",
      "Texto generado:  corte de madrid, y poner barcán\n",
      "del balegrías con ligandicio, y\n",
      "entre volverellemos terros. por mansos tarquite gloriosas corazón de tratinga, se dejímeza, hallábamos, tras en aquel sifornosmente no.  fin habiluría de segullar; ideas parte, auqtere con nuestro ibandes corucaba que un ofrciel ciblor de mi madre nos podienar madr\n",
      "\n",
      "Epoch 8/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7797 - categorical_accuracy: 0.5017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 0.2\n",
      "Seed:            y dejé los negocios públicos \n",
      "Texto generado:  y dejé los negocios públicos con la marina y algunas de la escuadra. con el\n",
      "combate de cuando en la casa, y cuando me parece que la parecía sus amores de la nacia, y con este me había construido en la cabeza de la vida y después de la escuadra en aquella escuadra con esta para de contestar el marinero de la escuadra en aquella \n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 0.5\n",
      "Seed:            y dejé los negocios públicos \n",
      "Texto generado:  y dejé los negocios públicos en su cariño, y al ver amor para mí mis amos el combate de la\n",
      "escuadra. sus barcos para mis estados el navío de la mar de la muerte de su mano, y su marido de proa a la terrible de la mar. a mi amo en abriozar a\n",
      "la casa, y no contemplaban a la escuadra en el cual había pasado mi estrecho rató en el \n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 1.0\n",
      "Seed:            y dejé los negocios públicos \n",
      "Texto generado:  y dejé los negocios públicos agonías... ¡oh!, era\n",
      "paquitán, y otra casi tenían llamite. la presencia maría como un josé por desaparezados en la pacha, que vestina a si cuenta detoncia por demente del consueno, porque ni embarcar una flo, agrazados comús si no pudses ineplacables de comprena de lay de muralesa, y nos enterían pe\n",
      "\n",
      "------> Epoch: 8 - Generando texto con temperature 1.2\n",
      "Seed:            y dejé los negocios públicos \n",
      "Texto generado:  y dejé los negocios públicos argo de\n",
      "ella?»\n",
      " podrás es que posía raías.\n",
      "\n",
      "--hallás geleión.  «¡metivo, decásame desponso: «lo más salvar, si él, y yataria era coltó en verzamen y las que los cañón...\n",
      "verdíamos muchos, y como abapiraliería mañana detreavilles, donde ésta que decía llegar cardendo ingléxicoojo, acordaba ora, y o p\n",
      "\n",
      "Epoch 9/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7680 - categorical_accuracy: 0.4265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 0.2\n",
      "Seed:           l, unido a lo que\n",
      "después he s\n",
      "Texto generado: l, unido a lo que\n",
      "después he sido de la casa. el _san juan_, de la mar con invento a mi amo por los marineros de la parte de la cosa. pero el casco de la grande en esta fuerte de la primera de la casa de la casa, y al mar viejo de este menos de estas personas de la casa. el _san juan_, el _san\n",
      "juan_, el _san juan_, el _san juan_\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 0.5\n",
      "Seed:           l, unido a lo que\n",
      "después he s\n",
      "Texto generado: l, unido a lo que\n",
      "después he sido hombre, esperando el mar a casa un poco poco por de su verdaderos--, por aquí nos encontró a la escuadra en su primera trasbordo de la noche, y el marinero de mano, y el _san juan_ y el _san hermenegild_, para que se encontró a cádiz, en la cola. no digo de este marcial, y desde el _trinidad_, n\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 1.0\n",
      "Seed:           l, unido a lo que\n",
      "después he s\n",
      "Texto generado: l, unido a lo que\n",
      "después he sin peligro de hallada, escrifundo por sorpresa muy pasarle, y la gana de lo que se colochón de lo que cada, y dijo: «¡no recho reporo, que estarse cibó porque se extigara en el largo de abriclería y de los crepor de ascerlado, nfuestraca por un almí tal dispojo, con lo que una ifan curazón pero de l\n",
      "\n",
      "------> Epoch: 9 - Generando texto con temperature 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:           l, unido a lo que\n",
      "después he s\n",
      "Texto generado: l, unido a lo que\n",
      "después he sido forte?\n",
      "\n",
      "avá extrego cerebra-masestalmente, quilo no se puede _mo, tranquitos se rubioraron laga, pareccó a frase que se deserroe con gente el orguxto de el _santa ala_, atravesos perocteron que en inquientaduras!»\n",
      "\n",
      "su amor de un arrmucha reprose corrándiendos, se presentó de los medifices. el ri\n",
      "\n",
      "Epoch 10/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7581 - categorical_accuracy: 0.4290\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 0.2\n",
      "Seed:           ba al golpe de las balas. yo l\n",
      "Texto generado: ba al golpe de las balas. yo le dijo al _san juan_, el\n",
      "_san juan_ el _san juan_, el _san juan_ el _san juan_ el _trinidad_ del _san juan_ el _san juan_ el _trinidad_, que lo que están apenas para que se ahora, y el muerto de la escuadra de su cuerpo, en la conversación de la escuadra combate de cuantos marineros a la cara de mar\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 0.5\n",
      "Seed:           ba al golpe de las balas. yo l\n",
      "Texto generado: ba al golpe de las balas. yo le dijo aquellos sitios puedo en su salvación se acabó los pies, que mandaba la maniobra con una enterible\n",
      "contrama, señor de la madre, y tan perecer en el combate de cuesta para los demás de las cosas ingleses, nos demás te recibió al cielo marcial había como objeto de la popa de conservar una pose.\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 1.0\n",
      "Seed:           ba al golpe de las balas. yo l\n",
      "Texto generado: ba al golpe de las balas. yo la alentó la mismo\n",
      "malestibad por la mar, cuando ni llarándoles a decis; la lenes chumpríacía, me conferencia que andala, el velante, y la mana?--por íamo a lo que lu pueble, sin encigirle echar aquel caspar rataje; pareciéndome el viejo se. dirigía el destrinavo, pues, arrostrado volver, así a todos\n",
      "\n",
      "------> Epoch: 10 - Generando texto con temperature 1.2\n",
      "Seed:           ba al golpe de las balas. yo l\n",
      "Texto generado: ba al golpe de las balas. yo luegrá infañé cosas platas, si quieo por comprenidazero». pedezones\n",
      "glotinamente aquellos junto mayoras». por escesas nos diré una gapa. la\n",
      "naciamante, que glorieres del poco a bardo malespleta.\n",
      "regrese doña sin puerto eniedido el 19.\n",
      "\n",
      "»midede, era tabados que no habe hecho seforré, y los suertos hab\n",
      "\n",
      "Epoch 11/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7494 - categorical_accuracy: 0.3740\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 0.2\n",
      "Seed:           empo\n",
      "indecoroso negar mi valor\n",
      "Texto generado: empo\n",
      "indecoroso negar mi valoria en la casa de la escuadra de la escuadra de la escuadra de la escuadra de la marine se de encontrada con tan grandes de la ordenada de la escuadra de la escuadra de la cabeza de la escuadra de la cabeza de la escuadra de la maridad de los cañones de la escuadra en la cabeza de su marido con la ma\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 0.5\n",
      "Seed:           empo\n",
      "indecoroso negar mi valor\n",
      "Texto generado: empo\n",
      "indecoroso negar mi valoria de los barcos hasta el peligro de la barda de la escuadra del _santa ana_ y les debaba a casa de esto, y la desalia, aunque en el momento de un cañón como tal cortespajo, como también de los cuales de la vida. esta noche, y mi amo con el combate de mi pañole, y el solo de la lengua de la escuadra\n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 1.0\n",
      "Seed:           empo\n",
      "indecoroso negar mi valor\n",
      "Texto generado: empo\n",
      "indecoroso negar mi valoresción, si se _espasacía_, habrían venidos en aquella todos las rudas construidas del lojo, cimas talpas de los dispuestos y barcos; pero señas d. alonso a conostre de vejer con su voz de las desventuras y la lámares: por buce, así me hiblo milente conciaba al fruolero había al alundad de horas tan \n",
      "\n",
      "------> Epoch: 11 - Generando texto con temperature 1.2\n",
      "Seed:           empo\n",
      "indecoroso negar mi valor\n",
      "Texto generado: empo\n",
      "indecoroso negar mi valor nouto».»\n",
      "\n",
      "\n",
      "--volvio--fento--. pero eúlica venisen yo, no eran ver lo tan arrojo, admistende complé napoles en invierte ingunde llenada, tresíamos para comenaciones újose doben ya de mi cuando a cual era una par del casada. de estodurar cercamuplate, que lincámes, imálidas cricisa que fue su falútid\n",
      "\n",
      "Epoch 12/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7419 - categorical_accuracy: 0.3679\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 0.2\n",
      "Seed:           e les envuelva en el coy[5]; p\n",
      "Texto generado: e les envuelva en el coy[5]; pues no pudo dios que la proa por tanto de marcial se presentaban a la mar. a mi amo con el\n",
      "sollado de mi amo.\n",
      "\n",
      "--el _san agustín_, si a la escuadra. estoy si no pudo contentarme a la cara acudía en el combate de la cabeza de la martinicalente. me parece que la escuadra de la marina estaba de mi amit\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 0.5\n",
      "Seed:           e les envuelva en el coy[5]; p\n",
      "Texto generado: e les envuelva en el coy[5]; pero eso se veo a después\n",
      "de su artiviendo.\n",
      "\n",
      "en todas las propias insistenciaban de la martinición, sin poder mis ojos en el primer marinero de la cara naval de trafal de casa la parte. su antigua de la prima de la parte, y estas estarones que le dijo a la prima de la\n",
      "rey de la servida de la bala, y \n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 1.0\n",
      "Seed:           e les envuelva en el coy[5]; p\n",
      "Texto generado: e les envuelva en el coy[5]; puesen el pierno nada me decíro del mar. en desgraciarse el _santa ana_; pero ello que que interesas, y dobo que no pudieran traves, cuando si no puede que todo tras, aunque era ésta para él que para ahora?»\n",
      "\n",
      "dejende de mi espíritu se sabía si decina, cuyos a la expedición más de ese que uno de los q\n",
      "\n",
      "------> Epoch: 12 - Generando texto con temperature 1.2\n",
      "Seed:           e les envuelva en el coy[5]; p\n",
      "Texto generado: e les envuelva en el coy[5]; pues no tembrá llega y cayó del servio tomara; el princón taña fasía menía dar también y estoy su primación aún no me muy bullueza supuél en la cabeza, casi como nadaba que me diorinun hazaba, y en seferme a la vozgia hamena: un ésto asormó él en importunté el trapal, no precetió el palotio sostano d\n",
      "\n",
      "Epoch 13/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.7352 - categorical_accuracy: 0.3676\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 0.2\n",
      "Seed:           s con el primer trapo\n",
      "de color\n",
      "Texto generado: s con el primer trapo\n",
      "de color de la cabeza, y con el momento de la contencia a la escuadra de su propio de la cabeza, y el mismo de la cabeza de su espíritu del marinero_, y el _santa\n",
      "ana_, se entre la de la parte de la consecuencia, y como el primero de la del parecer de su padre de la balandra de la\n",
      "noche en la costa, y al al\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 0.5\n",
      "Seed:           s con el primer trapo\n",
      "de color\n",
      "Texto generado: s con el primer trapo\n",
      "de color de los horroros de la cabeza, y después de viendo a la contesta y vi a atención, y no se había conocido en cádiz, porque no se apros de consideraba entre de algunas palabras de la de triste confiadores. pero algunos ver socedor, al fin de seres de mi\n",
      "amo. algunos marineros se\n",
      "almasan con el castill\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 1.0\n",
      "Seed:           s con el primer trapo\n",
      "de color\n",
      "Texto generado: s con el primer trapo\n",
      "de colorado, hasta trofe de aquella inevilada: ese siegría mi antocen en aquel mares, y en turmina que fuera suguer por la pierna. no ven comprendían ocurridos, que no sé ve esos frases fueran de paca, y no se gravencias respentaba en la cabe porque después del historo, arrobenturo en los migates retroy, ca\n",
      "\n",
      "------> Epoch: 13 - Generando texto con temperature 1.2\n",
      "Seed:           s con el primer trapo\n",
      "de color\n",
      "Texto generado: s con el primer trapo\n",
      "de color, señar el _arto_, acbiligiosos de la de orgunquiles hombres nacionaros. lo que, por los rjofecedos si. por dominalmiendo evitarno y quien había conteje: «yo niños aún: encontrando ya, pensoma la parandres tierra mover. a la bohaba _serta era _san justa_, le treídose al _vandanar les fins. volvierog\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 159s 317us/step - loss: 0.7293 - categorical_accuracy: 0.3710\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 0.2\n",
      "Seed:           ón, la serenidad, la\n",
      "inquebran\n",
      "Texto generado: ón, la serenidad, la\n",
      "inquebranda se contesta a la escuadra de la cabeza de la tripulación de la escuadra de la contestación de la contemplación de la cabeza de la mar con interés. los primeros de las cosas parados para que no se acabaron en el combate de aquella noche es que le había de esta se descupa en el combate de su antesp\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 0.5\n",
      "Seed:           ón, la serenidad, la\n",
      "inquebran\n",
      "Texto generado: ón, la serenidad, la\n",
      "inquebranta tía moral su correra, y se le de las alemnas de la cabeza, y la impresión de aquella acción de la bahía. como ésta se había auxilio de la de mi amo, el primero de la escuadra de la bala. el _san juan_ era un moles de la escuadra en la cara de las piezas de los ingleses, que el barco de las cosas \n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 1.0\n",
      "Seed:           ón, la serenidad, la\n",
      "inquebran\n",
      "Texto generado: ón, la serenidad, la\n",
      "inquebrante contestuaba el próxigo baclado en ellas en los simboles de ciñónitas, era que el buen, ya, que el punto parece cañonapa de mi amo, que siempre que a, no le imagen la melora. esta más parte el _bahal_.\n",
      "nuestras los prisioneros, escenas del _arrogenej_ soche el año: el peligro seguísidado corré esp\n",
      "\n",
      "------> Epoch: 14 - Generando texto con temperature 1.2\n",
      "Seed:           ón, la serenidad, la\n",
      "inquebran\n",
      "Texto generado: ón, la serenidad, la\n",
      "inquebrantajeza de aquello? lobrar de sus frías a ti, no sielo o habres de las españolas, la invélacer al, exclamos hermos con mesando a las maniobras de su san paqua de las vistas famirándos en bocas rostracionemos. las aquéllas no trataban lo turbar, heridos de hasta arval zafaciobles: álava se había sido \n",
      "\n",
      "Epoch 15/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.7239 - categorical_accuracy: 0.3724\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 0.2\n",
      "Seed:           o, verdadero relámpago negro q\n",
      "Texto generado: o, verdadero relámpago negro que se encontraba a su semblante, y la completa con la costa de mi infelicencia, y en la compasión a los cañones que\n",
      "nos será tan grave estaba mis ojos con la podería, y como se disparaba en mi compañero y marineroso, y como si se le atraves en la costa de la\n",
      "manora entre los ingleses, y a los señore\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 0.5\n",
      "Seed:           o, verdadero relámpago negro q\n",
      "Texto generado: o, verdadero relámpago negro que en\n",
      "la balandra con sus andalos de la noche estaba por el mismo en que se le había\n",
      "esposa y mal había hasta que marcial y allí en aquellos momentos y más fuertes de la mar sobre el _san juan_, sin duda con la mar con en el alcázar de la mar san agua de su sentimiento. en un cañonazo no se había po\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 1.0\n",
      "Seed:           o, verdadero relámpago negro q\n",
      "Texto generado: o, verdadero relámpago negro que la vista, que entonces muy bion a rían de aquella noticia no\n",
      "fual que es ois celebros cualertes.\n",
      "\n",
      "marcial inglesé en público sin muy difición que era buen tiempo, pues la conversación partiendas por mal hasto estaba parecida por aquí sin amo, la conver menor el bueno; que esto observa y a los not\n",
      "\n",
      "------> Epoch: 15 - Generando texto con temperature 1.2\n",
      "Seed:           o, verdadero relámpago negro q\n",
      "Texto generado: o, verdadero relámpago negro quedea año, que\n",
      "pececil en valor poco azote.\n",
      "\n",
      "regres columnas en bona lo más salía, inquierada a bordo y parencia era fuerte. come sientro es sila, hasta de\n",
      "resoncionalo: en sus barmanos sintió\n",
      "la ha de estos efequientos o ahoganso cañonazos y díginacilla. estos desastres en visitarnis. de ática comp\n",
      "\n",
      "Epoch 16/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.7190 - categorical_accuracy: 0.4055\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 16 - Generando texto con temperature 0.2\n",
      "Seed:           ue; a pesar del desmayo de la \n",
      "Texto generado: ue; a pesar del desmayo de la contestación, y el comandante en el combate del _santa\n",
      "ana_ de aquel modo de la escuadra por el alcázar y en el _santa ana_ de un navío de la escuadra de la cabeza de sus cabezas en la contestación de la escuadra de la cabeza de sus contrarios se acabaron a la costa de la vida y después de artillerí\n",
      "\n",
      "------> Epoch: 16 - Generando texto con temperature 0.5\n",
      "Seed:           ue; a pesar del desmayo de la \n",
      "Texto generado: ue; a pesar del desmayo de la aria escuadra. las olas escenas a la casa, porque la\n",
      "provecho estaba de marcial para que a los navíos».\n",
      "\n",
      "--pero qué señora, que estoy san francés, al agua de agua insultar por la vez inglésticia. aún no se le dijo al _santa ana_; pero alguna en el combate con apunta con algunas marinerías por la gue\n",
      "\n",
      "------> Epoch: 16 - Generando texto con temperature 1.0\n",
      "Seed:           ue; a pesar del desmayo de la \n",
      "Texto generado: ue; a pesar del desmayo de la grandia\n",
      "la primera combate no se han levo al hérolon, y\n",
      "entre todo allína de las ansiamiatemuna, como se vuedo--simeré al _santa ana_, con la casa se hubiera fijaban la maniobra aún seguí mandado seis irsantió bala y creyado.\n",
      "\n",
      "«yo semo, fracosan a mis cirujando que antes bien en su poderonca suelcid\n",
      "\n",
      "------> Epoch: 16 - Generando texto con temperature 1.2\n",
      "Seed:           ue; a pesar del desmayo de la \n",
      "Texto generado: ue; a pesar del desmayo de la consecuadrar el latuor_ hasta el pairón que estavo consagado.\n",
      "corría de hienre iluximor, y atardábamos y pele: lo hibienta produjo a las natulladas el viento rustosa, y..fila tenía gran ganasa toda él arto vez en las ragzas barse; no cesaba antes de pequullarse algo y engana de las mayores ilesa duñ\n",
      "\n",
      "Epoch 17/30\n",
      "500000/500000 [==============================] - 160s 319us/step - loss: 0.7145 - categorical_accuracy: 0.4069\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 17 - Generando texto con temperature 0.2\n",
      "Seed:           ue allí se me trataba con mimo\n",
      "Texto generado: ue allí se me trataba con mimos en que le acordarían en la casa de su amigo. el\n",
      "_san juan_, de 112 cañones que se le habían advertir en el combate. el _trinidad_, y el _trinidad_, no se allaban de la vida, que se allaban de algunas palabras de la noche del cañones de la cabeza, y el _santa ana_, que se allaban de la maniobra, se\n",
      "\n",
      "------> Epoch: 17 - Generando texto con temperature 0.5\n",
      "Seed:           ue allí se me trataba con mimo\n",
      "Texto generado: ue allí se me trataba con mimos a la cubierta. por las dos prisioneros\n",
      "que la manda a su espíritu, pues...» nosotros me descupo de mi amo. corrí a la más victoria que pero servir, al punto aquella acerión se alguna a su herido, y estaba de contestar mi mante cual perecido, para algún paso, y el peligro a la paz, y al menos en aq\n",
      "\n",
      "------> Epoch: 17 - Generando texto con temperature 1.0\n",
      "Seed:           ue allí se me trataba con mimo\n",
      "Texto generado: ue allí se me trataba con mimos a la parenta.\n",
      "\n",
      "en tierra hundar de un fan abrá. la lancia de la obligadora defordad? ¿qué recir es habar jamás....»\n",
      "\n",
      "una calla a doña flora, querían cortar a la gravedad atente, habría se había olo: menos a aquella columna y desde este mismo a la casaya\n",
      "profundo almunacio con objeto rogaño, y apen\n",
      "\n",
      "------> Epoch: 17 - Generando texto con temperature 1.2\n",
      "Seed:           ue allí se me trataba con mimo\n",
      "Texto generado: ue allí se me trataba con mimosión había díreche a\n",
      "sabio hás, chaquilla, por como un rabo, decirá que yo; su casa se afectarí; heraba aún se cosa de bonateaza, y nada a veo lijos de argulor; le habé como crepultar, hasta los rizos.  esto navío grave hoy gallientos con estas. capitán en fondosa, retoy, y comimién volvían a costad\n",
      "\n",
      "Epoch 18/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.7105 - categorical_accuracy: 0.3984\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 18 - Generando texto con temperature 0.2\n",
      "Seed:           guerra,\n",
      "y hasta llegó a hacers\n",
      "Texto generado: guerra,\n",
      "y hasta llegó a hacerse de mi amo, que se habían aguado a la casa de la cabeza de su espacio de aquella cosa. no pudo siempre se habían aguado a la casa, el comandante en la casa me acercaba en el casco de la cabeza, y en la cabeza no se ahogaba de la cabeza, y en la cabeza y como el teniente arrojados a la casa de la ca\n",
      "\n",
      "------> Epoch: 18 - Generando texto con temperature 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:           guerra,\n",
      "y hasta llegó a hacers\n",
      "Texto generado: guerra,\n",
      "y hasta llegó a hacerse que en la caleta y en la cabeza y la impaciencia de repaguardo a un cuarto. nos parecía que nos donde la discurría su antiguo, y le dijo a la\n",
      "cosa entonces al marinero de aquella mortal considerando interesas primeros de la manora proyectica, como a los capertos, y las grandes no\n",
      "habían soldado de\n",
      "\n",
      "------> Epoch: 18 - Generando texto con temperature 1.0\n",
      "Seed:           guerra,\n",
      "y hasta llegó a hacers\n",
      "Texto generado: guerra,\n",
      "y hasta llegó a hacerse, que ni una segunid de aquella límete avegía que puese siempre. nada muy nfoco repeso, al histo, y atacados... pero, la pulpadas combate a có por absorbullaje pronto que en vejer--¿pero fue, mal hombre de dios, no volver e hoy herá todo interaran. se acostira a basco: aunta moven despojo, y perdie\n",
      "\n",
      "------> Epoch: 18 - Generando texto con temperature 1.2\n",
      "Seed:           guerra,\n",
      "y hasta llegó a hacers\n",
      "Texto generado: guerra,\n",
      "y hasta llegó a hacerse. que gravinados en acharnoso oficiales nos bromas nazaran». ¡ah! hacedas que quiso:\n",
      " otra me llama no, objetados a cansar, y frgurando por muz cómbato, que tivome en la que la zacha! pues bueno de los ingleses! inipada existínibles que yo observaba las dolaciones nacemitaban vistiambianhas y sí, n\n",
      "\n",
      "Epoch 19/30\n",
      "500000/500000 [==============================] - 160s 319us/step - loss: 0.7067 - categorical_accuracy: 0.3971\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 19 - Generando texto con temperature 0.2\n",
      "Seed:           ada navío había ocurrido una t\n",
      "Texto generado: ada navío había ocurrido una tranquilizad de la escuadra combinada de la escuadra de la escuadra de la escuadra combate de aquella tristeza con la cabeza y la confusaba de su propia al mar con la casa. el\n",
      "_san juan_, y al mismo tiempo no era muy bien en casa de la escuadra estaba de mi amo, el comandante al mar, el _san juan_, d\n",
      "\n",
      "------> Epoch: 19 - Generando texto con temperature 0.5\n",
      "Seed:           ada navío había ocurrido una t\n",
      "Texto generado: ada navío había ocurrido una tranquilizad de los que he dicho hasta el _san ildefonso_ se prodeccí en el primer castigo, y el mismo se embarque era para el construido de la terrible estaron, por siempre se arrastraba y con su muerte inglés.\n",
      "\n",
      "--¡me referible de que yo tan años, me dijeron que la escuadra de que la escuadra combin\n",
      "\n",
      "------> Epoch: 19 - Generando texto con temperature 1.0\n",
      "Seed:           ada navío había ocurrido una t\n",
      "Texto generado: ada navío había ocurrido una tranquía, y la banabrazada enteráme: cartó fará y restaño, lo primero, y fue la pasa, alontaba con que es cargó la canumena costazón. por gloriosos corazones tan aunos, _dejótiva_, el de una escaradros de la más memoria con el teniente parte de sublir. no quería santa por el bonsado, y se nos hallé c\n",
      "\n",
      "------> Epoch: 19 - Generando texto con temperature 1.2\n",
      "Seed:           ada navío había ocurrido una t\n",
      "Texto generado: ada navío había ocurrido una tembo de serembrametavento\n",
      "se darió mi condemata en vez, contestarme con la ecasado\n",
      "sobre el navío, era segundo; el amaroso de su tiempo mandó de cisnavo enlacanza. así punta vez sernaciones impoligció con rodillas, flotando embo, obligándome el añogeza crimos perseguitos y más: el nerocero no pueder\n",
      "\n",
      "Epoch 20/30\n",
      "500000/500000 [==============================] - 162s 325us/step - loss: 0.7031 - categorical_accuracy: 0.3918\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 20 - Generando texto con temperature 0.2\n",
      "Seed:           oz martirio las purificó de to\n",
      "Texto generado: oz martirio las purificó de todos los dos navíos, como un par de la parte de la caleta no se les asociaban tan pronto de mi amo en la\n",
      "completo invención, porque estaba en el cabo de la escuadra de la casa de la cara del\n",
      "_trinidad_ el _santa ana_120, el _rayo_ y el _santa ana_, el _san juan_ embarcó en mi amo en la cabeza, y en e\n",
      "\n",
      "------> Epoch: 20 - Generando texto con temperature 0.5\n",
      "Seed:           oz martirio las purificó de to\n",
      "Texto generado: oz martirio las purificó de todos los diestros, las hermanas de mi encuentro a estribor, ni estaba mucho con alguna ora el contra\n",
      "el _santa ana_120, el _san juan_ en el combate del _santa ana_, el _san juan_ de por el enemigo pasado de la casa, el viento estaba tan resolucio que en la cara se había de la idea de la después, como\n",
      "\n",
      "------> Epoch: 20 - Generando texto con temperature 1.0\n",
      "Seed:           oz martirio las purificó de to\n",
      "Texto generado: oz martirio las purificó de toca, cácitan su caredaje, sime ándolo conocido para la tripulación y volvían sin sueje\n",
      "malespina. fue a las casas\n",
      "durante yo podían polver de mí, sin recretar conocir, quienes que indicría obre todos quitar ni todos compaños inglés para sía que no\n",
      "es presante para constiparya a él jarazotes instrisas\n",
      "\n",
      "------> Epoch: 20 - Generando texto con temperature 1.2\n",
      "Seed:           oz martirio las purificó de to\n",
      "Texto generado: oz martirio las purificó de tormía y malditivas. por juva otra, pudo, nuestro anigeres dicen... donté dibiérse idersulamerpicador--; nse la escotumbró si abría llegosa; tuve temeré en que entonte de quiera, admiraba satudencia, porque la arean travesco: restría, hablando en pésado desde en tresinaletes perdidas y verlas, también\n",
      "\n",
      "Epoch 21/30\n",
      "500000/500000 [==============================] - 165s 330us/step - loss: 0.6999 - categorical_accuracy: 0.3839\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 21 - Generando texto con temperature 0.2\n",
      "Seed:           venía a casa borracho\n",
      "como una\n",
      "Texto generado: venía a casa borracho\n",
      "como una operación de la escuadra, y si tenía marcial, si por último, si tiene a la escuadra. pero no me habría sido de su artillería, y cuando en el combate del _santa ana_ del\n",
      "_rayo_ de un navío en la naciona en el _rayo_, de algunos navíos estaba de la escuadra combate de mi amita escuadra de la marina i\n",
      "\n",
      "------> Epoch: 21 - Generando texto con temperature 0.5\n",
      "Seed:           venía a casa borracho\n",
      "como una\n",
      "Texto generado: venía a casa borracho\n",
      "como una operación de aguas y demos acabas, si me ha sido de aquel tiempo que si fuera de su aguterral proyectio de la victoria, a pesar de tan barco que imperible hacia la mano salvarnos, y arriados de su marino, y el espacio de su superioridad del mar todo el _santa ana_, el _san juan_, la gran\n",
      "defendaba \n",
      "\n",
      "------> Epoch: 21 - Generando texto con temperature 1.0\n",
      "Seed:           venía a casa borracho\n",
      "como una\n",
      "Texto generado: venía a casa borracho\n",
      "como unas propias de todos, y como aires la grave. le escapa usted era para diversación de un hombre. esto que quiere vendando la imfrecia por el acto.\n",
      "\n",
      "--pues ollató sin que la voz de mío, me ocuptíuimo a escedilo, y... ¡qué vivue engen de desora uno. un definiéndolo ni una fante peda. di posiñiento, asoci\n",
      "\n",
      "------> Epoch: 21 - Generando texto con temperature 1.2\n",
      "Seed:           venía a casa borracho\n",
      "como una\n",
      "Texto generado: venía a casa borracho\n",
      "como unas operaciones a guardia?. puestos se casado siempre por las nativieres, y este\n",
      "quito que le hazoban si sigo--. allíama churtu. la que iba auxilio sólo inteteral vucho.\n",
      "\n",
      "es cajo es difícil andre; me proparota de sus humoritas calmados; frenés lo menor... cuando pensaba tercerones de que la imaginada,\n",
      "\n",
      "Epoch 22/30\n",
      "500000/500000 [==============================] - 165s 331us/step - loss: 0.6968 - categorical_accuracy: 0.3774\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 22 - Generando texto con temperature 0.2\n",
      "Seed:           cia mí, trémulo de gozo, y con\n",
      "Texto generado: cia mí, trémulo de gozo, y con los navíos estaban de mi amo, el comandante al contrario de los piezas que\n",
      "nos acercó a la mayor parte de la costa de mi amo.\n",
      "\n",
      "--¿y el _san agustín_ se dirigió a casa de la cabeza y la artillería en que se presentaba a los marinos, y la contrarión de la primera de la consecución a los marinos que n\n",
      "\n",
      "------> Epoch: 22 - Generando texto con temperature 0.5\n",
      "Seed:           cia mí, trémulo de gozo, y con\n",
      "Texto generado: cia mí, trémulo de gozo, y con los que había que mi amo, el navío de alonso serían la cabeza, que\n",
      "disparó por mi amo por los barcos ingleses, y cada vez me llama a los navegantes de este noche, y en el suelo de los que he contado. yo no le han a pasar de su amar a las cosas pintas de mi tiempo por el magno. llegará al combate de\n",
      "\n",
      "------> Epoch: 22 - Generando texto con temperature 1.0\n",
      "Seed:           cia mí, trémulo de gozo, y con\n",
      "Texto generado: cia mí, trémulo de gozo, y con la vista marina entrara\n",
      "no sirves el tragué, y cierta encarna pódiciente la fancipina, dos navíos en que el servicio. nuestros mil oblegados era tan fin, y sentima se habría llevado y me había londrado las empartas, perfonce mi exicencia, cuál del primer ojo es que me encontraba li primera, delida \n",
      "\n",
      "------> Epoch: 22 - Generando texto con temperature 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:           cia mí, trémulo de gozo, y con\n",
      "Texto generado: cia mí, trémulo de gozo, y con un formido mentía\n",
      "furiosación en su buena nobse pesamó, su heraron querpeqneme, cosa nueva contradiz mí:\n",
      "mentirarse que alabras, séñole, que es y yo se quisiera, fue píquimis que tanto, no parecían:  quien cistado, salía y momentolita y digo estuvieran otra es este movimiento, a la facha, que todo\n",
      "\n",
      "\n",
      "Epoch 23/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.6938 - categorical_accuracy: 0.3814\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 23 - Generando texto con temperature 0.2\n",
      "Seed:           desarbolado y\n",
      "fuera de combate\n",
      "Texto generado: desarbolado y\n",
      "fuera de combate, y el mismo tiempo se presentó a la marinería de la boda que el primer cañonazo propio de la paz. el antigu¿y después de la escuadra estaba muy años parte de la escuadra, y se contendó a la escuadra combinada de la cabeza y con su esposa con tan desesperación de la cabeza, y se dirigía la mano de m\n",
      "\n",
      "------> Epoch: 23 - Generando texto con temperature 0.5\n",
      "Seed:           desarbolado y\n",
      "fuera de combate\n",
      "Texto generado: desarbolado y\n",
      "fuera de combate, y el muelle que alguna de marcha a la vida, y le dijeron que el servicio de la de su buque, y en el mismo tempir de la cabeza y con venida\n",
      "ambiado se me hice con dios. algunos momentos en desorden de la escuadra,\n",
      "que no era mucho después de algunas para que se presentara al amanecer de aquello obr\n",
      "\n",
      "------> Epoch: 23 - Generando texto con temperature 1.0\n",
      "Seed:           desarbolado y\n",
      "fuera de combate\n",
      "Texto generado: desarbolado y\n",
      "fuera de combate. así hora herido, ni podía atraron en casa comprendido a ver la\n",
      "mandaga. recuerdo así:\n",
      "\n",
      "--extemarando en teniente suspacio, y las bodróa y cuando quede aquello noveció encima cuenta por\n",
      "cobarde. seguro a bordo del almaroto de vaiga contra el venciente, romotiva definilla familada me representaron a\n",
      "\n",
      "------> Epoch: 23 - Generando texto con temperature 1.2\n",
      "Seed:           desarbolado y\n",
      "fuera de combate\n",
      "Texto generado: desarbolado y\n",
      "fuera de combate; chiquis a tierra y si conocer no nominiante hacer atriclo, y dros seis nuevas y mante, pues sentir algujo inosación, y gran engañona fistición al paso propia de lócedia. ¡también de mi poctinuido. un día gandal asques bailantes de las bodegas de briarsivo que carritan en mis sentidios!, me que dej\n",
      "\n",
      "Epoch 24/30\n",
      "500000/500000 [==============================] - 161s 321us/step - loss: 0.6911 - categorical_accuracy: 0.3902\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 24 - Generando texto con temperature 0.2\n",
      "Seed:           contramos a tiro de pistola de\n",
      "Texto generado: contramos a tiro de pistola de la cabeza, y como la conversación a la cabeza, que se habían contado de mi amo.\n",
      "\n",
      "--pues en la cabeza se aprojaba en mis personales de la cabeza, que le dijeron con mucha\n",
      "gravedad. en el marinero de la cabeza de su cabeza, que le había\n",
      "esposa y sin poder de mi amo.\n",
      "\n",
      "--eso es el mismo tiempo, y en el\n",
      "\n",
      "------> Epoch: 24 - Generando texto con temperature 0.5\n",
      "Seed:           contramos a tiro de pistola de\n",
      "Texto generado: contramos a tiro de pistola de su conducidad que la conversación a dios, y no se conocía a la abandaje de mi amita. después de este modo de la casa de la angustia, porque la redetal de la\n",
      "proa de su muerte. después de esto se propósito de la patria hasta el mástil unos, aunque en mí. el vento\n",
      "así dirigiariado estas oírones que s\n",
      "\n",
      "------> Epoch: 24 - Generando texto con temperature 1.0\n",
      "Seed:           contramos a tiro de pistola de\n",
      "Texto generado: contramos a tiro de pistola de unas ineviteblas, confiaba una criadula del jaticido al sens voces\n",
      "o entener.\n",
      "\n",
      "ahora aparecido su pintumente excelente vistado. sagusentara que su endemballero, ya periedió del mozo alcanzado del patrio. en los heridos, muchas contertos atacado... quiéndase\n",
      "cada en aquellos restondelías, y cuando r\n",
      "\n",
      "------> Epoch: 24 - Generando texto con temperature 1.2\n",
      "Seed:           contramos a tiro de pistola de\n",
      "Texto generado: contramos a tiro de pistola desparia! ecendió todo el próximo que había cámaran: «ya se fundía, proeció la izapamentada fue grandes consideraba completaba yo, su puesto nos de las si nos poviermos a parecer. y, que no pudiera llevado la pena de misasa.\n",
      "\n",
      "mita que en vejer, ni antesté a mi amo, incólordiz, fuera que andaje por des\n",
      "\n",
      "Epoch 25/30\n",
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.6886 - categorical_accuracy: 0.3853\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 25 - Generando texto con temperature 0.2\n",
      "Seed:           onto...\n",
      "\n",
      "le diré a usted cómo \n",
      "Texto generado: onto...\n",
      "\n",
      "le diré a usted cómo se lo me llamaban el _san juan_, que se después de la costa, el combate el muelle era muy disparo, su contrarierte, y el más vivo en que la desgracia y mi amo, el\n",
      "primer en la cabeza y el fin de la cabeza y la consecución de la costa de los desordenados por las casas.\n",
      "\n",
      "--¡ahoga!».\n",
      "\n",
      "contemplando el e\n",
      "\n",
      "------> Epoch: 25 - Generando texto con temperature 0.5\n",
      "Seed:           onto...\n",
      "\n",
      "le diré a usted cómo \n",
      "Texto generado: onto...\n",
      "\n",
      "le diré a usted cómo se puso a la escuadra.\n",
      "\n",
      "--y que estaba mucha contenta de marcial, que es desarbolares de los palos de sus cosas personas de su profecido. el\n",
      "_san hermenegilado_ 180r dicho más mirante, y casi de los hombres que pasaba, pronto a un servicio de su despecto el de los cuartos... si no quiera siete, el\n",
      "p\n",
      "\n",
      "------> Epoch: 25 - Generando texto con temperature 1.0\n",
      "Seed:           onto...\n",
      "\n",
      "le diré a usted cómo \n",
      "Texto generado: onto...\n",
      "\n",
      "le diré a usted cómo hablar mientras veridones! pues, creí que le hacer por el _rayo_, dijo de la líntardo del marinero de los ingleses trabajos de la petridad.\n",
      "entonces ausado el servicio, y él disposición recordas a la escaleza. recrendiéndonos crecían vivales que cortesían a narrarca si la mano; por las casas siguien\n",
      "\n",
      "------> Epoch: 25 - Generando texto con temperature 1.2\n",
      "Seed:           onto...\n",
      "\n",
      "le diré a usted cómo \n",
      "Texto generado: onto...\n",
      "\n",
      "le diré a usted cómo maría, estos esconarles, singulados en muchas voces que sólo el misterro bien chicipo de júnsta?» provesiparán, roparan labía, desahogo para que la corazón aventiaba. elornos navíos vida, a bordo detarme, de casi nersando aquel arboladado.\n",
      "\n",
      "los ofendilé epusos géstos así pecco de tiempe, que era mal\n",
      "\n",
      "Epoch 26/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.6860 - categorical_accuracy: 0.3867\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 26 - Generando texto con temperature 0.2\n",
      "Seed:           --¡a tierra! ¡todos vamos a ti\n",
      "Texto generado: --¡a tierra! ¡todos vamos a tierra!»\n",
      "\n",
      "no estaba más para mí lo que es decir, después de algunas con el combate. aquello se aceró de casa de los barcos de la cara. el _san juan_ el _rayo_ dio la muerte de la cabeza de su marido con interés y los demás de la bahía. el _san agustín_, el _san juan_ hermos de la casa de su comandante\n",
      "\n",
      "------> Epoch: 26 - Generando texto con temperature 0.5\n",
      "Seed:           --¡a tierra! ¡todos vamos a ti\n",
      "Texto generado: --¡a tierra! ¡todos vamos a tierra!--exclamó mil pelas en aquella ocasión de los navíos españoles a la dar al contrario, y mi amo, el norte de la cámara. había hecho me hizo al amanece con de los marineros de contraria en cuatro. si no puedo a tierra la guerra del patrio contra el mismo combate, y sin embargo, de la vida a lo pu\n",
      "\n",
      "------> Epoch: 26 - Generando texto con temperature 1.0\n",
      "Seed:           --¡a tierra! ¡todos vamos a ti\n",
      "Texto generado: --¡a tierra! ¡todos vamos a tierría? ¿qué en tierra, si pludamente a todos y caso distancia la ormenta, foldaban de numero de tal dóventar; obligada: me dilitaba desde aquel hombre de los barcos, que han de dios algo muerta. si intertuna, a la lancconeración tenía que se ganaba a los trasbordinos en mi amita, que dijo el _rayo_ \n",
      "\n",
      "------> Epoch: 26 - Generando texto con temperature 1.2\n",
      "Seed:           --¡a tierra! ¡todos vamos a ti\n",
      "Texto generado: --¡a tierra! ¡todos vamos a tierra!»,\n",
      "de esos sdiradas, tuvioron que soy hice una pie. dijo que me reíslo que no puedo dio fuerzamente rodad su proyectido. era sus fue, y tombarionembotable, taboría que los\n",
      "careñados rescuendo el uno que por los muy\n",
      "volga? doz divisiflicarnado, y el 20 despuéspa, abreor dirigiendo la initiláteru\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 159s 318us/step - loss: 0.6838 - categorical_accuracy: 0.3912\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 27 - Generando texto con temperature 0.2\n",
      "Seed:           eados\n",
      "por él, ya traducidos a \n",
      "Texto generado: eados\n",
      "por él, ya traducidos a la marina de los navíos estuvieron al _santísima trinidad_, el _san juan_ era un tiempo a la escuadra de la cabeza y con tan balazo de los navíos estuvieron a la escuadra. con la conferencia de la de los desastres de la maniferta, si no había constumbre, que se le abandonaban algunos navíos en la co\n",
      "\n",
      "------> Epoch: 27 - Generando texto con temperature 0.5\n",
      "Seed:           eados\n",
      "por él, ya traducidos a \n",
      "Texto generado: eados\n",
      "por él, ya traducidos a lo menos de cañón. en el combate de su antigua combate.\n",
      "\n",
      "muerto dio fuera de babor, sino ser viento.\n",
      "\n",
      "--pues en la habita concediano se apresaba el _neptune_, el _san juan_ en que le dijeron con mucho de mi amita.\n",
      "\n",
      "después de alentar con tanta disparación con la costa, donde estaba hacer una horrend\n",
      "\n",
      "------> Epoch: 27 - Generando texto con temperature 1.0\n",
      "Seed:           eados\n",
      "por él, ya traducidos a \n",
      "Texto generado: eados\n",
      "por él, ya traducidos a nuestra lían con ambosavemidad, al mismo, creo, si\n",
      "lis a los cuarentes hondados de sus mandados, y le dijeron con los venidos, honramentos en la\n",
      "noche esperaba aunque era la lanzante inglés que, dicen ustedes, come posible momento de manejar o porque embarcarse comar hantarles terdían los colegas, a\n",
      "\n",
      "------> Epoch: 27 - Generando texto con temperature 1.2\n",
      "Seed:           eados\n",
      "por él, ya traducidos a \n",
      "Texto generado: eados\n",
      "por él, ya traducidos a poneho de dovensias acompaduedo en fal74»...\n",
      "habría sido chisido a lay de bajar y fuenectero. era cañón un grito de nuestro orbate de verlación.\n",
      "juvo que puede imposible mayor a mi hallaciento.\n",
      "\n",
      "--deos voces\n",
      "a lo que ley _nocheta_--respibibre de la obscuridad de ganales de mi correrá quiene ; ¿québs\n",
      "\n",
      "Epoch 28/30\n",
      "500000/500000 [==============================] - 160s 319us/step - loss: 0.6815 - categorical_accuracy: 0.3903\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 28 - Generando texto con temperature 0.2\n",
      "Seed:           bajo de hacerlo.\n",
      "\n",
      "se mandó res\n",
      "Texto generado: bajo de hacerlo.\n",
      "\n",
      "se mandó resta contra el _santa ana_, el _san juan_ del _santa ana_ de aquel cornezando en el _trinidad_, y al menor de la cabeza y el comandante meses era tan penotivo a la desgracia, y el mismo tiempo no me acercó a mi amo de mi madre, y el mismo tiempo no pudo transpordar a la mañana de mi\n",
      "espíritu, al menos\n",
      "\n",
      "------> Epoch: 28 - Generando texto con temperature 0.5\n",
      "Seed:           bajo de hacerlo.\n",
      "\n",
      "se mandó res\n",
      "Texto generado: bajo de hacerlo.\n",
      "\n",
      "se mandó resto del marinero de la escuadra por el contra nuestro. seguir a la cubierta de nuestra línea de mis amos se encontraba a malespina. pero para\n",
      "que verdarnos a la escuadra, entonces no es decir al combate. los profestrando el estrancio, y que no me escaban la contraria de la mañana de proa de desgracia\n",
      "\n",
      "------> Epoch: 28 - Generando texto con temperature 1.0\n",
      "Seed:           bajo de hacerlo.\n",
      "\n",
      "se mandó res\n",
      "Texto generado: bajo de hacerlo.\n",
      "\n",
      "se mandó resorvado a mi amo, y las numpañes años habersavecimiento, observaba la metrozo que indicaba desde treiz en inglate, y firme de selvimiento ampara decidido a que fuera de mí, me indicaba el _trinidad_ un extremo a la misma edad de los que mandando dio o cazana, pero despacho, y al mío que tan ama, fuer\n",
      "\n",
      "------> Epoch: 28 - Generando texto con temperature 1.2\n",
      "Seed:           bajo de hacerlo.\n",
      "\n",
      "se mandó res\n",
      "Texto generado: bajo de hacerlo.\n",
      "\n",
      "se mandó resiativarse farma flacad, meterín cielos enemigo de la suy acidada sin prenda; pero des filablas que si era ilesa pesaba hasta el inglés\n",
      "por temeroste cerezco, aquel hombre de mi tierra, y quién dirá mahena, según meses debía gravedad. había descupo de mismal: feímasmería.\n",
      "\n",
      "no vosulaba, sumamos penas \n",
      "\n",
      "Epoch 29/30\n",
      "500000/500000 [==============================] - 160s 320us/step - loss: 0.6795 - categorical_accuracy: 0.3949\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 29 - Generando texto con temperature 0.2\n",
      "Seed:            aquel papel por otro alguno, \n",
      "Texto generado:  aquel papel por otro alguno, y al fin, se le acabaron de la contemplación de su espíritu la costumbre. entonces estaba de su espíritu en la cabeza, y como la destreiza de marcial, se después de algunos navíos en la contemplación y allí no se asombraban a la mar con la contestación de su viaje a pesar de su consuelta.\n",
      "\n",
      "marcial d\n",
      "\n",
      "------> Epoch: 29 - Generando texto con temperature 0.5\n",
      "Seed:            aquel papel por otro alguno, \n",
      "Texto generado:  aquel papel por otro alguno, sin duda de su espíritu en el castillo de la idea de la patria; se confiesta en mi oído con la cual es principio.\n",
      "\n",
      "el sueve cada buen resto de su espíritu la costumbre. por los navíos se casaconecían a la corte de pasar el transforma que me\n",
      "ha de escosciar de un corte al comandante de su costumbre, \n",
      "\n",
      "------> Epoch: 29 - Generando texto con temperature 1.0\n",
      "Seed:            aquel papel por otro alguno, \n",
      "Texto generado:  aquel papel por otro alguno, la boda censara a la terpera no sestase era desorden, objuto de ansiegas ¡púniles, puesto los sano y un instante la\n",
      "doradura y desde que se servían consigna más trasladadas del navío. así que querían sido ambos hasta los dos recuerdos. mientras de hasta tomar de\n",
      "cádiz frenteres de hombres, ya conser\n",
      "\n",
      "------> Epoch: 29 - Generando texto con temperature 1.2\n",
      "Seed:            aquel papel por otro alguno, \n",
      "Texto generado:  aquel papel por otro alguno, sin suerpo como los barcos jampunos.\n",
      "\n",
      "aunda, vez me tuve renovil, ocuprón de inglaterra y gripsamen,, con estamiento gloridado\n",
      "despeñación, o terramos vienes, auce cayeros en cual momonichó churrumvezaj. haber edado me caída más más alta térmillen, no fuen a treí sobre collingwood que se hallaba nos\n",
      "\n",
      "Epoch 30/30\n",
      "500000/500000 [==============================] - 159s 319us/step - loss: 0.6776 - categorical_accuracy: 0.3979\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------> Epoch: 30 - Generando texto con temperature 0.2\n",
      "Seed:           grosando la voz y poniéndose m\n",
      "Texto generado: grosando la voz y poniéndose me parecía\n",
      "a marcial, y en la caleta no pude creyero que le arrastraba a cádiz, y el viento en la caleta de la\n",
      "corte de mar y algunas palabras de la caleta. construido en la casa me acaba a mi amo con la caleta, y el\n",
      "_san juan_ hasta el marinero de la caleta de su campaña y a la patria de mi amo.\n",
      "\n",
      "--\n",
      "\n",
      "------> Epoch: 30 - Generando texto con temperature 0.5\n",
      "Seed:           grosando la voz y poniéndose m\n",
      "Texto generado: grosando la voz y poniéndose me permitió en el\n",
      "sollado como azuleres de la terrible llegado, y el enemigo se averío».\n",
      "\n",
      "--¡oh!, ¡qué vaya a carcuco, y si no pude ver los oficiales a la casa.\n",
      "\n",
      "--¿y yo sería sólo por algún brazo? el mar como cosa es que les construirían a pesar de su carañate, y el\n",
      "_san juan_ del _santa ana_, el _s\n",
      "\n",
      "------> Epoch: 30 - Generando texto con temperature 1.0\n",
      "Seed:           grosando la voz y poniéndose m\n",
      "Texto generado: grosando la voz y poniéndose matan--me pidé reprimir. marcial\n",
      "al soleje, distronados sobre las ovecias de muchas baltadas últamo, que otra muerto a la caña desprésegió por sus momentos imagincciones de seguir andar de la fuerza, de miemple se alomnas, se había explicado de poca fuerza, permanecía el mar. el muno, y sus personame\n",
      "\n",
      "------> Epoch: 30 - Generando texto con temperature 1.2\n",
      "Seed:           grosando la voz y poniéndose m\n",
      "Texto generado: grosando la voz y poniéndose mi enajalga. pero estos\n",
      "lejantotes guerreronas en el que le\n",
      "_tenbaran le aigurioron; fleja, de un ninto algazona, estreagura que real requidioso, que habían divertido su irramitante cañones del ignocio para, dos hombres que valirís... ¿y prisusto más o juguere a haceran enviar de las, feían, por lo p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ahora si entrenamos\n",
    "batch_size = 128\n",
    "epochs     = 30\n",
    "\n",
    "h = model.fit([X_enc, X_dec], y_dec, batch_size=batch_size, epochs=epochs, callbacks=[generation_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1baa86c128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficamos el entrenamiento\n",
    "f, axes = plt.subplots(1,2, figsize=(15, 8))\n",
    "\n",
    "x = np.arange(len(h.history['loss']))+1\n",
    "ax = axes[0]\n",
    "ax.plot(x, h.history['loss'], 'r-o')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Train loss')\n",
    "ax.set_ylim((0.0,2.5))\n",
    "ax.set_xlim((min(x),max(x)))\n",
    "ax.grid()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(x, h.history['categorical_accuracy'],  'r-o')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Train accuracy')\n",
    "ax.set_ylim((0.0,1.0))\n",
    "ax.set_xlim((min(x),max(x)))\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Salvamos el entrenamiento\n",
    "model.save('seq2seq.kmodel')\n",
    "encoder_model.save('encoder_model.kmodel')\n",
    "decoder_model.save('decoder_model.kmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios\n",
    "- Se pudo entrenar construir un modelo seq2seq y se lo entrenó con extractos del dataset \"Trafalgar\"\n",
    "- Se comprendió el funcionamiento de la arquitectura seq2seq, tanto en entrenamiento como en predicción\n",
    "- Se útilizó un tamaño de 30 caracteres para la sequencia de entrada y 10 caracteres en la sequencia de salida.\n",
    "- Se observó el mismo comportamiento observado en el ejercicio anterior durante el entrenamiento del modelo. En un principio el modelo no podía escribir ninguna palabra. El modelo empezó aprendiendo primero a separar con espacios las palabras y usar las letras más probables (dejando de lado los símbolos de puntuación). Luego pudo aprender a formar palabras completas y finalemente aplió su vocabulario.\n",
    "- Se la curva de loss se puede ver que el modelo entrenó con una buena pendiente hasta la época 10 y después le costó seguir aprendiendo. Se observa que aunque podría seguir su entrenamiento y seguiría aprendiendo aún más.\n",
    "\n",
    "### Salida\n",
    "La salida observada para la época 30 del entrenamiento resultó:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "------> Epoch: 30 - Generando texto con temperature 0.2\n",
    "Seed:           grosando la voz y poniéndose m\n",
    "Texto generado: grosando la voz y poniéndose me parecía\n",
    "a marcial, y en la caleta no pude creyero que le arrastraba a cádiz, y el viento en la caleta de la\n",
    "corte de mar y algunas palabras de la caleta. construido en la casa me acaba a mi amo con la caleta, y el\n",
    "_san juan_ hasta el marinero de la caleta de su campaña y a la patria de mi amo.\n",
    "\n",
    "--\n",
    "\n",
    "------> Epoch: 30 - Generando texto con temperature 0.5\n",
    "Seed:           grosando la voz y poniéndose m\n",
    "Texto generado: grosando la voz y poniéndose me permitió en el\n",
    "sollado como azuleres de la terrible llegado, y el enemigo se averío».\n",
    "\n",
    "--¡oh!, ¡qué vaya a carcuco, y si no pude ver los oficiales a la casa.\n",
    "\n",
    "--¿y yo sería sólo por algún brazo? el mar como cosa es que les construirían a pesar de su carañate, y el\n",
    "_san juan_ del _santa ana_, el _s\n",
    "\n",
    "------> Epoch: 30 - Generando texto con temperature 1.0\n",
    "Seed:           grosando la voz y poniéndose m\n",
    "Texto generado: grosando la voz y poniéndose matan--me pidé reprimir. marcial\n",
    "al soleje, distronados sobre las ovecias de muchas baltadas últamo, que otra muerto a la caña desprésegió por sus momentos imagincciones de seguir andar de la fuerza, de miemple se alomnas, se había explicado de poca fuerza, permanecía el mar. el muno, y sus personame\n",
    "\n",
    "------> Epoch: 30 - Generando texto con temperature 1.2\n",
    "Seed:           grosando la voz y poniéndose m\n",
    "Texto generado: grosando la voz y poniéndose mi enajalga. pero estos\n",
    "lejantotes guerreronas en el que le\n",
    "_tenbaran le aigurioron; fleja, de un ninto algazona, estreagura que real requidioso, que habían divertido su irramitante cañones del ignocio para, dos hombres que valirís... ¿y prisusto más o juguere a haceran enviar de las, feían, por lo p\n",
    "```\n",
    "\n",
    "\n",
    "- Se observa que el modelo para temperaturas bajas, forma muchas más palabras legibles.\n",
    "- Para temperaturas altas se anima a utilizar más signos de puntuación y baja la cantidad de la palabras con sentido, si bien las \"palabras\" formada tienen buena estructura.\n",
    "- Se destaca la línea: ```--¿y yo sería sólo por algún brazo? el mar como cosa es que les construirían```. Utilizó símbolos para marcar una línea de diálogo, además formuló una pregunta (aunque sin sentido) y le agregó las símbolos de pregunta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python_3_TF_GPU ",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
